{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we update and improve the agents and environments presented in `rl_opts.rl_framework`. Two main changes:\n",
    "\n",
    "- we use `numba` to improve speed.\n",
    "- we implement more efficient ways of updating the H and G matrix (contribution by Dr. Michele Caraglio).\n",
    "- we consider as base case `num_agents = 1`. In previous versions we had this as an input which overcomplicated all functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp numba.rl_framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# Libs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class that defines the foraging environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba.experimental import jitclass\n",
    "from numba import jit, float64, int64, bool_, prange, njit\n",
    "import math\n",
    "import random\n",
    "#from rl_opts.utils import isBetween_c_Vec, coord_mod\n",
    "NOPYTHON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| exec: false\n",
    "# for debugging\n",
    "NOPYTHON = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isBetween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@jit(nopython = NOPYTHON)\n",
    "def isBetween_c_Vec_numba(a, b, c, r):\n",
    "        \"\"\"\n",
    "        Checks whether point c is crossing the line formed with point a and b.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        a : tensor, shape = (1,2)\n",
    "            Previous position.\n",
    "        b : tensor, shape = (1,2)\n",
    "            Current position.\n",
    "        c : tensor, shape = (Nt,2)\n",
    "            Positions of all targets.\n",
    "        r : int/float\n",
    "            Target radius.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mask : array of boolean values\n",
    "            True at the indices of found targets.\n",
    "\n",
    "        \"\"\"\n",
    "        if (a == b).all():\n",
    "            return np.array([False]*c.shape[0])\n",
    "\n",
    "        mask = np.array([True]*c.shape[0])\n",
    "        \n",
    "        dotproduct = (c[:, 0] - a[0]) * (b[0] - a[0]) + (c[:, 1] - a[1])*(b[1] - a[1])\n",
    "        squaredlengthba = (b[0] - a[0])*(b[0] - a[0]) + (b[1] - a[1])*(b[1] - a[1])\n",
    "        \n",
    "        #exclude the targets whose vertical projection of the vector c-a w.r.t. the vector b-a is larger than the target radius.\n",
    "        idx = np.argwhere(np.abs(numba.np.arraymath.cross2d(b-a, c-a))/np.linalg.norm(b-a) > r) \n",
    "        for i1 in idx:\n",
    "            mask[i1] = False        \n",
    "        \n",
    "        #exclude the targets whose scalar product is negative (they are on the other side of the step direction)\n",
    "        for i2 in np.argwhere(dotproduct < 0):\n",
    "            mask[i2] = False\n",
    "\n",
    "        #exclude the targets that are beyond the step.\n",
    "        for i3 in np.argwhere(dotproduct > squaredlengthba):\n",
    "            mask[i3] = False\n",
    "            \n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "compiling = isBetween_c_Vec_numba(np.array([0.1,1]), np.array([1,3]), np.random.rand(100,2), 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.24 µs ± 7.62 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit isBetween_c_Vec_numba(np.array([0.1,1]), np.array([1,5]), np.random.rand(100,2), 0.00001)\n",
    "# Run time of new version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from rl_opts.utils import isBetween_c_Vec as oldbetween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.2 µs ± 2.9 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit oldbetween(np.array([0.1,1]), np.array([1,3]), np.random.rand(100,2), 0.00001)\n",
    "# Run time of older version:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@jit(nopython = NOPYTHON)\n",
    "def pareto_sample(alpha : float, # Exponent of the power law\n",
    "                  xm : float, # Minimun value of the distribution\n",
    "                  size : int=1 # Number of samples\n",
    "                 )-> np.array : # Samples from the distribution\n",
    "    ''' Generates samples from a Pareto distribution of given parameters '''\n",
    "    samples = np.zeros(size)\n",
    "    for ii in range(size):\n",
    "        u = random.random()  # Uniform random variable between 0 and 1\n",
    "        x = xm / (u ** (1 / alpha))\n",
    "        samples[ii] = x\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random sampling from array with probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@jit(nopython = NOPYTHON)\n",
    "def rand_choice_nb(arr : np.array, # 1D numpy array of values to sample from.\n",
    "                   prob : np.array # 1D numpy array of probabilities for the given samples.\n",
    "                  ): # Random sample from the given array with a given probability.    \n",
    "    return arr[np.searchsorted(np.cumsum(prob), np.random.random(), side=\"right\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TargetEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@jitclass([(\"target_positions\", float64[:,:]) ,\n",
    "           (\"current_rewards\", float64[:]) ,\n",
    "           (\"kicked\", float64[:]) ,\n",
    "           (\"current_directions\", float64[:]) ,\n",
    "           (\"positions\", float64[:,:]),\n",
    "           (\"previous_pos\", float64[:,:]),\n",
    "           (\"lc\", float64[:,:]),\n",
    "           (\"mask\", bool_[:]),\n",
    "           (\"first_encounter\", float64[:,:])])\n",
    "class TargetEnv():\n",
    "    Nt : int\n",
    "    L : float\n",
    "    r : float\n",
    "    lc : np.array\n",
    "    agent_step : float\n",
    "    num_agents : int\n",
    "    destructive_targets : bool\n",
    "    target_positions : np.ndarray\n",
    "    current_rewards : np.array\n",
    "    kicked : np.array\n",
    "    current_directions : np.array\n",
    "    positions : np.array\n",
    "    previous_pos : np.array\n",
    "    mask : np.array\n",
    "    first_encounter : np.array\n",
    "    lc_distribution : str\n",
    "    \n",
    "    \n",
    "    def __init__(self,\n",
    "                 Nt = 10, # blabla\n",
    "                 L = 1.3,\n",
    "                 r = 1.5,\n",
    "                 lc = np.array([[1.0],[1]]),\n",
    "                 agent_step = 1,\n",
    "                 num_agents = 1,\n",
    "                 destructive = False,\n",
    "                 lc_distribution = 'constant'):\n",
    "        \n",
    "        \"\"\"        \n",
    "        Class defining the foraging environment. It includes the methods needed to place several agents to the world.\n",
    "        \n",
    "        Updated from `rl_framework.TargetEnv`:        \n",
    "            > `lc_distribution`: now allows to consider different distributions. lc now means different things depending on the distribution.\n",
    "            > `TargetEnv.update_pos_disp`: allows to update the position of the agent with a given displacement.            \n",
    "            \n",
    "        **Inputs**\n",
    "        \n",
    "        `Nt` : (int) \n",
    "            Number of targets.\n",
    "            \n",
    "        `L` : (int)\n",
    "            Size of the (squared) world.\n",
    "            \n",
    "        `r` : (int) \n",
    "            Radius with center the target position. It defines the area in which agent detects the target.\n",
    "            \n",
    "        `lc` \n",
    "            Cutoff length. Displacement away from target (to implement revisitable targets by displacing agent away from the visited target).\n",
    "            \n",
    "        `agent_step`: (int, optional)\n",
    "            Displacement of one step. The default is 1.\n",
    "            \n",
    "        `num_agents`: (int, optional)\n",
    "            Number of agents that forage at the same time. The default is 1.\n",
    "            \n",
    "        `destructive`: (bool, optional)\n",
    "            True if targets are destructive. The default is False.\n",
    "            \n",
    "        `lc_distribution`: (str) Chosee between 'power_law', 'pareto' and None. Depending on the previous, lc has different meanings:\n",
    "        \n",
    "        > `power_law` : lc is sampled from a power law x^{-1-alpha} where alpha = self.lc.flatten()[0] \n",
    "        \n",
    "        > `pareto` : lc is sampled from a Pareto distribution with alpha = self.lc.flatten()[0] and x_minim = self.lc.flatten()[0]\n",
    "        \n",
    "        > `None` : if len(lc) == 1, then that's the lc. If len(lc) > 1, then samples an lc considering vals = lc[0] and probabilities = lc[1]\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.Nt = Nt\n",
    "        self.L = L\n",
    "        self.r = r\n",
    "        self.lc = lc\n",
    "        self.agent_step = agent_step \n",
    "        self.num_agents = num_agents\n",
    "        self.destructive_targets = destructive\n",
    "        self.lc_distribution = lc_distribution\n",
    "        \n",
    "\n",
    "        self.init_env()\n",
    "        \n",
    "    def init_env(self):\n",
    "        \"\"\"\n",
    "        Environment initialization.\n",
    "        \"\"\"\n",
    "        self.target_positions = np.random.rand(self.Nt, 2)*self.L\n",
    "        \n",
    "        #store who is/was rewarded\n",
    "        self.current_rewards = np.zeros(self.num_agents)\n",
    "        \n",
    "        #signal whether agent has been kicked\n",
    "        self.kicked = np.zeros(self.num_agents)\n",
    "        \n",
    "        #set positions and directions of the agents\n",
    "        self.current_directions = np.random.rand(self.num_agents)*2*np.pi\n",
    "        self.positions = np.random.rand(self.num_agents, 2)*self.L\n",
    "        self.previous_pos = self.positions.copy()       \n",
    "\n",
    "        \n",
    "\n",
    "    def update_pos(self, change_direction, agent_index = 0):        \n",
    "        \"\"\"\n",
    "        Updates information of the agent depending on its decision.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        change_direction : bool\n",
    "            Whether the agent decided to turn or not.\n",
    "        agent_index : int, optional\n",
    "            Index of the given agent. Default is 0.\n",
    "        \"\"\"        \n",
    "        # Save previous position to check if crossing happened\n",
    "        self.previous_pos[agent_index] = self.positions[agent_index].copy()\n",
    "        \n",
    "        if change_direction:\n",
    "            self.current_directions[agent_index] = random.uniform(0,1)*2*math.pi\n",
    "        \n",
    "        #Update position\n",
    "        self.positions[agent_index][0] = self.positions[agent_index][0] + self.agent_step*np.cos(self.current_directions[agent_index])\n",
    "        self.positions[agent_index][1] = self.positions[agent_index][1] + self.agent_step*np.sin(self.current_directions[agent_index])\n",
    "        \n",
    "    def update_pos_disp(self, \n",
    "                        displacement, # tuple or array stating (disp_x, disp_y)\n",
    "                        agent_index = 0 # index of the agent. Only matters for collective experiments\n",
    "                       ):\n",
    "        \"\"\"\n",
    "        Updates the position of the agent based on the input displacement\n",
    "        \"\"\"\n",
    "        # Save previous position to check if crossing happened\n",
    "        self.previous_pos[agent_index] = self.positions[agent_index].copy()\n",
    "        \n",
    "        #Update position\n",
    "        self.positions[agent_index][0] = self.positions[agent_index][0] + displacement[0]\n",
    "        self.positions[agent_index][1] = self.positions[agent_index][1] + displacement[1]\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def check_encounter(self):\n",
    "        \"\"\"\n",
    "        Checks whether the agent found a target, and updates the information accordingly.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        agent_index : int, optional\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        True if the agent found a target.\n",
    "\n",
    "        \"\"\"       \n",
    "        agent_index = 0\n",
    "        encounters = isBetween_c_Vec_numba(self.previous_pos[agent_index], self.positions[agent_index], self.target_positions, self.r)\n",
    "        \n",
    "        if sum(encounters) > 0: \n",
    "            \n",
    "            #if there is more than 1 encounter, pick the closest to the agent.\n",
    "            if sum(encounters) == 1:\n",
    "                first_encounter = np.argwhere(encounters == True).flatten()\n",
    "            else:\n",
    "                # compute the distance from the previous position to each target            \n",
    "                distance_previous_pos = np.sqrt((self.previous_pos[agent_index][0]- self.target_positions[:, 0])**2 + (self.previous_pos[agent_index][1] - self.target_positions[:, 1])**2)            \n",
    "                \n",
    "                # checking which encountered point is closer to previous position\n",
    "                min_distance_masked = np.argmin(distance_previous_pos[encounters])\n",
    "                first_encounter = np.argwhere(encounters == True)[min_distance_masked].flatten()\n",
    "            if self.destructive_targets:\n",
    "                self.target_positions[first_encounter] = np.random.rand(2)*self.L\n",
    "            else:\n",
    "                #----KICK----\n",
    "                # If there was encounter, we reset direction and change position of particle to (pos target + lc)\n",
    "                kick_direction = np.random.uniform(low = 0, high = 2*np.pi)\n",
    "                for idx_first in first_encounter: # This is super weird!\n",
    "                    if self.lc_distribution == 'power_law':\n",
    "                        # when we have the power law, the first value of lc is considered to be the exponent.\n",
    "                        # The following samples from a power law x^{-1-alpha} where alpha = self.lc.flatten()[0]                        \n",
    "                        current_lc = (1-random.uniform(0,1))**(-1/self.lc.flatten()[0])\n",
    "\n",
    "                    elif self.lc_distribution == 'pareto':\n",
    "                        # Sampling from Pareto. Here alpha = self.lc.flatten()[0] and x_minim = self.lc.flatten()[0]\n",
    "                        current_lc = pareto_sample(self.lc[0,0], self.lc[1,0])[0]\n",
    "                    else:\n",
    "                        # if lc has a single element, take that one as lc, if not sample\n",
    "                        current_lc = self.lc.flatten()[0] if len(self.lc.flatten()) == 2 else rand_choice_nb(arr = self.lc[0], prob = self.lc[1])\n",
    "                    self.positions[agent_index][0] = self.target_positions[idx_first, 0] + current_lc*np.cos(kick_direction)\n",
    "                    self.positions[agent_index][1] = self.target_positions[idx_first, 1] + current_lc*np.sin(kick_direction)\n",
    "                self.kicked[agent_index] = 1\n",
    "                #------------\n",
    "                \n",
    "            #...and we add the information that this agent got to the target\n",
    "            self.current_rewards[agent_index] = 1              \n",
    "            return 1\n",
    "        \n",
    "        else: \n",
    "            self.kicked[agent_index] = 0\n",
    "            self.current_rewards[agent_index] = 0\n",
    "            return 0   \n",
    "        \n",
    "    def check_bc(self):\n",
    "        \"\"\"\n",
    "        Updates position coordinates of agent agent_index to fulfill periodic boundary conditions.\n",
    "\n",
    "        \"\"\"\n",
    "        agent_index=0\n",
    "        self.positions[agent_index] = (self.positions[agent_index])%self.L\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Runtime testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from rl_opts.numba.rl_framework import TargetEnv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TargetEnv(Nt = 1000,\n",
    "                      L = 123,\n",
    "                      r = 50,\n",
    "                      lc = np.array([[0.1],[1]]),\n",
    "                      lc_distribution = 'pareto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19 µs ± 7.96 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit env.check_encounter()\n",
    "# Runtime of env.check_encounter():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_opts.rl_framework import TargetEnv as TargetEnv_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oenv = TargetEnv_classic(Nt = 100,\n",
    "                         L = 123,\n",
    "                         r = 0.2,\n",
    "                         lc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 µs ± 211 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit oenv.check_encounter()\n",
    "# Runtime of oenv.check_encounter():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk from policy\n",
    "\n",
    "These replicate what we were doing in `rl_opts.learn_and_bench.walk_from_policy` and help get efficiencies for fixed policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "@jit(nopython = NOPYTHON)\n",
    "def single_agent_walk(N_runs : int, # Total number of runs / episodes to evaluate\n",
    "                      time_ep : int, # Length of each run / episode\n",
    "                      policy : np.array, # Policy of the walker\n",
    "                      env : object# Environment where the walker moves\n",
    "                     )-> np.array :  # Array containing the number of targets from in each run\n",
    "\n",
    "    \"\"\"\n",
    "    Walk of a single in env of type TargetEnv given a policy. Performance is evaluated as the number of targets found in a fixed time time_ep.\n",
    "    \"\"\"\n",
    "    \n",
    "    save_rewards = np.zeros(N_runs)\n",
    "    \n",
    "    for ep in range(N_runs):\n",
    "        #initialize environment and agent's counter and g matrix\n",
    "        env.init_env()\n",
    "        agent_state = 0\n",
    "\n",
    "        for t in range(time_ep):\n",
    "            \n",
    "            if t == 0 or env.kicked[0]:\n",
    "                # change direction\n",
    "                env.update_pos(1)\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                #reset counter\n",
    "                agent_state = 0\n",
    "                #set kicked value to false again\n",
    "                env.kicked[0] = 0\n",
    "                \n",
    "            else: \n",
    "                # decide\n",
    "                action = 0 if policy[0, agent_state] > np.random.rand() else 1\n",
    "                #update positions\n",
    "                env.update_pos(action)\n",
    "                #check if target was found + kick if it is\n",
    "                reward = env.check_encounter()\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                # update agent_state\n",
    "                agent_state += 1\n",
    "                \n",
    "                save_rewards[ep] += reward\n",
    "                \n",
    "    return save_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@jit(nopython = NOPYTHON, parallel = True)\n",
    "def multi_agents_walk(N_runs : int, # Total number of runs / episodes to evaluate\n",
    "                      time_ep : int, # Length of each run / episode\n",
    "                      N_agents : int, # Number of agents to consider\n",
    "                      Nt = 100, # Number of targets in the environment\n",
    "                      L = 100, # Size of the environment\n",
    "                      r = 0.5, # Radius of the targets\n",
    "                      lc = 1.0, # Parameters of lc distribution or lc itself \n",
    "                      agent_step = 1, # Length of agent's step\n",
    "                      destructive_targets = False, # True if targets are destructive. The default is False. \n",
    "                      lc_distribution = 'constant', # lc distribution\n",
    "                      policy = [[1,1], [0,0]] # Policy of the agents\n",
    "              )-> np.array : # Array containing number of targets found for each agent at each run.\n",
    "    \"\"\"\n",
    "    Runs in parallel single_agent_walk. Due to numba props, we need to give all parameters as inputs (see source).\n",
    "    \"\"\"\n",
    "    \n",
    "    save_rewards = np.zeros((N_agents, N_runs))\n",
    "    \n",
    "    for n_agent in prange(N_agents):\n",
    "        \n",
    "        env = TargetEnv(Nt,L,r,lc,agent_step,1,destructive_targets,lc_distribution)\n",
    "        \n",
    "        rews = single_agent_walk(N_runs, time_ep, policy, env) \n",
    "    \n",
    "        save_rewards[n_agent] = rews\n",
    "        \n",
    "    return save_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projective Simulation agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Base Forager\n",
    "Here we do the numba implementation of `rl_opts.rl_framework.Forager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@jitclass([(\"num_percepts_list\", int64[:]),           \n",
    "           (\"initial_prob_distr\", float64[:,:]),           \n",
    "           (\"fixed_policy\", float64[:,:]) ,\n",
    "           (\"h_matrix\", float64[:,:]) ,\n",
    "           (\"g_matrix\", float64[:,:]) ,\n",
    "           (\"h_0\", float64[:,:]),\n",
    "           ])\n",
    "class _Forager_original():\n",
    "    num_actions : int\n",
    "    gamma_damping : float\n",
    "    eta_glow_damping : float\n",
    "    policy_type : str\n",
    "    beta_softmax : float\n",
    "    num_percepts : int\n",
    "    agent_state : int\n",
    "    num_percepts_list : np.array\n",
    "    initial_prob_distr : np.array\n",
    "    fixed_policy : np.array    \n",
    "    h_matrix : np.array\n",
    "    g_matrix : np.array\n",
    "    h_0 : np.array\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_actions, # Number of actions\n",
    "                 state_space, \n",
    "                 # List where each entry is the state space of each perceptual feature. \n",
    "                 # In general we only consider one perceptual feature (counter)\n",
    "                 gamma_damping=0.0, # Gamma of PS\n",
    "                 eta_glow_damping=0.0, # Glow of PS\n",
    "                 policy_type='standard', # Sampling of policy\n",
    "                 beta_softmax=3, # Parameters if policy is softmax\n",
    "                 initial_prob_distr = np.array([[],[]]), # Initial h-matrix\n",
    "                 fixed_policy=np.array([[],[]]) # If considering a fixed policy\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Adapted to numba from rl_framework.Forager. This is an intermediate step to Forager with no efficient H and G updates.\n",
    "        To improve clarity we have changed num_percepts_list variable to state_space\n",
    "        \"\"\"\n",
    "        \n",
    "        self.agent_state = 0\n",
    "        \n",
    "        self.num_actions = num_actions       \n",
    "\n",
    "        \n",
    "        self.num_percepts_list = np.array([len(i) for i in state_space], dtype = np.int64) # change w.r.t PSAGENT\n",
    "        self.gamma_damping = gamma_damping\n",
    "        self.eta_glow_damping = eta_glow_damping\n",
    "        self.policy_type = policy_type\n",
    "        self.beta_softmax = beta_softmax\n",
    "        self.initial_prob_distr = initial_prob_distr\n",
    "        self.fixed_policy = fixed_policy\n",
    "        \n",
    "        self.num_percepts = int(np.prod(self.num_percepts_list)) # total number of possible percepts\n",
    "        \n",
    "        self.init_matrices()\n",
    "        \n",
    "    def init_matrices(self):\n",
    "\n",
    "        self.g_matrix = np.zeros((self.num_actions, self.num_percepts)) #glow matrix, for processing delayed rewards\n",
    "\n",
    "        # initialize h matrix with different values\n",
    "        if len(self.initial_prob_distr[0]) > 0:          \n",
    "            self.h_0 = self.initial_prob_distr\n",
    "            self.h_matrix = self.h_0.copy()\n",
    "        else: \n",
    "            self.h_matrix = np.ones((self.num_actions, self.num_percepts), dtype=np.float64) #Note: the first index specifies the action, the second index specifies the percept.\n",
    "            \n",
    "    def percept_preprocess(self, observation):\n",
    "        \"\"\"\n",
    "        Takes a multi-feature percept and reduces it to a single integer index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : ARRAY of integers >=0, of the same length as self.num_percepts_list\n",
    "            List that describes the observation. Each entry is the value that each feature takes in the observation.\n",
    "            observation[i] < num_percepts_list[i] (strictly)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        percept : int\n",
    "            Percept index that corresponds to the input observation.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        percept = 0\n",
    "        for which_feature in range(len(observation)):\n",
    "            percept += int(observation[which_feature] * np.prod(self.num_percepts_list[:which_feature]))\n",
    "        return percept\n",
    "    \n",
    "    def deliberate(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation , this method chooses the next action and records that choice in the g_matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : list\n",
    "            List that describes the observation, as specified in percept_preprocess.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        action : int\n",
    "            Index of the chosen action.\n",
    "\n",
    "        \"\"\"\n",
    "        percept = self.percept_preprocess(observation) \n",
    "        action = rand_choice_nb(arr = np.arange(self.num_actions), prob = self.probability_distr(percept))\n",
    "        self.g_matrix = (1 - self.eta_glow_damping) * self.g_matrix\n",
    "        self.g_matrix[action, percept] += 1 #record latest decision in g_matrix\n",
    "        return action\n",
    "    \n",
    "    def probability_distr(self, percept):\n",
    "        \"\"\"\n",
    "        Given a percept index, this method returns a probability distribution over actions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        percept : int\n",
    "            Index of the given percept.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probability_distr : np.array, length = num_actions\n",
    "            Probability for each action (normalized to unit sum), computed according to policy_type.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.policy_type == 'standard':\n",
    "            h_vector = self.h_matrix[:, percept]\n",
    "            probability_distr = h_vector / np.sum(h_vector)\n",
    "        elif self.policy_type == 'softmax':\n",
    "            h_vector = self.beta_softmax * self.h_matrix[:, percept]\n",
    "            h_vector_mod = h_vector - np.max(h_vector)\n",
    "            probability_distr = np.exp(h_vector_mod) / np.sum(np.exp(h_vector_mod))\n",
    "        return probability_distr\n",
    "    \n",
    "    def learn(self, reward):\n",
    "        \"\"\"\n",
    "        Given a reward, this method updates the h matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reward : float\n",
    "            Value of the obtained reward.\n",
    "        \"\"\"\n",
    "        if len(self.initial_prob_distr[0]) > 0:\n",
    "            self.h_matrix =  self.h_matrix - self.gamma_damping * (self.h_matrix - self.h_0) + reward * self.g_matrix\n",
    "        else:\n",
    "            self.h_matrix =  self.h_matrix - self.gamma_damping * (self.h_matrix - 1.) + reward * self.g_matrix\n",
    "            \n",
    "    def reset_g(self):\n",
    "        \"\"\"\n",
    "        Resets the g_matrix.\n",
    "        \"\"\"\n",
    "        self.g_matrix = np.zeros((self.num_actions, self.num_percepts), dtype=np.float64)\n",
    "        \n",
    "    def deliberate_fixed_policy(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation , this method chooses the next action according to the fixed policy specified as attribute of the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : list\n",
    "            List that describes the observation, as specified in percept_preprocess.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        action : int\n",
    "            Index of the chosen action.\n",
    "\n",
    "        \"\"\"\n",
    "        percept = self.percept_preprocess(observation) \n",
    "        if len(self.fixed_policy[0]) > 0:\n",
    "            action = rand_choice_nb(arr = np.arange(self.num_actions), prob = self.fixed_policy[percept])\n",
    "        else:\n",
    "            print('No fixed policy was given to the agent. The action will be selected randomly.')\n",
    "            action = np.random.choice(self.num_actions)\n",
    "    \n",
    "        self.g_matrix = (1 - self.eta_glow_damping) * self.g_matrix\n",
    "        self.g_matrix[action, percept] += 1 #record latest decision in g_matrix\n",
    "    \n",
    "        return action\n",
    "    \n",
    "    def act(self, action):\n",
    "        \"\"\"\n",
    "        Agent performs the given action.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : int (0, 1)\n",
    "            1 if it changes direction, 0 otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # If the agent changes direction   \n",
    "        if action == 1:\n",
    "            self.agent_state = 0\n",
    "        else:\n",
    "            self.agent_state += 1  \n",
    "            \n",
    "    \n",
    "    def get_state(self):  \n",
    "        ''' simplified to case of single forager. Returns list because is what deliberate needs'''\n",
    "        return np.array([self.agent_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No fixed policy was given to the agent. The action will be selected randomly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "#| exec : false\n",
    "agent = _Forager_original(num_actions = 2, state_space = np.array([np.arange(100)]))\n",
    "agent.percept_preprocess([0]*agent.num_percepts_list)\n",
    "agent.probability_distr(0)\n",
    "observation = [0]*agent.num_percepts_list[0]\n",
    "agent.deliberate(np.array(observation))\n",
    "agent.learn(1)\n",
    "agent.reset_g()\n",
    "agent.deliberate_fixed_policy(np.array(observation))\n",
    "agent.act(0)\n",
    "agent.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "## Forager with efficient H update\n",
    "We use the formula $H_{t+i} = (1-\\gamma)^i H_t + \\gamma H_0 \\sum_{j=1}^i(1-\\gamma)^{j-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@jitclass([(\"num_percepts_list\", int64[:]),           \n",
    "           (\"initial_prob_distr\", float64[:,:]),           \n",
    "           (\"fixed_policy\", float64[:,:]) ,\n",
    "           (\"h_matrix\", float64[:,:]) ,\n",
    "           (\"g_matrix\", float64[:,:]) ,\n",
    "           (\"h_0\", float64[:,:]),\n",
    "           (\"prefactor_1\", float64[:]),\n",
    "           (\"prefactor_2\", float64[:])\n",
    "          ])\n",
    "class _Forager_efficient_H():\n",
    "    num_actions : int\n",
    "    gamma_damping : float\n",
    "    eta_glow_damping : float\n",
    "    policy_type : str\n",
    "    beta_softmax : float\n",
    "    num_percepts : int\n",
    "    agent_state : int\n",
    "    max_no_update : int\n",
    "    counter_upd : int\n",
    "    num_percepts_list : np.array\n",
    "    initial_prob_distr : np.array\n",
    "    fixed_policy : np.array    \n",
    "    h_matrix : np.array\n",
    "    g_matrix : np.array\n",
    "    h_0 : np.array\n",
    "    prefactor_1: np.array\n",
    "    prefactor_2: np.array\n",
    "    \n",
    "    def __init__(self, num_actions, \n",
    "                 state_space, \n",
    "                 gamma_damping=0.0, \n",
    "                 eta_glow_damping=0.0, \n",
    "                 policy_type='standard', \n",
    "                 beta_softmax=3, \n",
    "                 initial_prob_distr = np.array([[],[]]), \n",
    "                 fixed_policy=np.array([[],[]]),\n",
    "                 max_no_update = int(1e4)\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Improved agent from _Agent_original with efficient H update implemented\n",
    "        \"\"\"\n",
    "        \n",
    "        self.agent_state = 0\n",
    "        \n",
    "        self.num_actions = num_actions\n",
    "        self.num_percepts_list = np.array([len(i) for i in state_space], dtype = np.int64) # change w.r.t PSAGENT\n",
    "        self.gamma_damping = gamma_damping\n",
    "        self.eta_glow_damping = eta_glow_damping\n",
    "        self.policy_type = policy_type\n",
    "        self.beta_softmax = beta_softmax\n",
    "        self.initial_prob_distr = initial_prob_distr\n",
    "        self.fixed_policy = fixed_policy\n",
    "        \n",
    "        self.num_percepts = int(np.prod(self.num_percepts_list)) # total number of possible percepts\n",
    "        \n",
    "        self.init_matrices()\n",
    "        \n",
    "        self.max_no_update = max_no_update      \n",
    "        self.counter_upd = 0\n",
    "        self.prefactor_1 = (1-self.gamma_damping)**(np.arange(self.max_no_update+1)) \n",
    "        # This is the slow / easy to understand way of computing prefactor_2\n",
    "        # self.prefactor_2 = np.zeros(self.max_no_H_update+1)       \n",
    "        # for i in range(self.max_no_H_update):\n",
    "        #     self.prefactor_2[i+1] = self.gamma_damping*np.sum((1-self.gamma_damping)**np.arange(i+1))\n",
    "        # and this it the efficient way\n",
    "        sum_term = (1-self.gamma_damping)**np.arange(self.max_no_update+1)\n",
    "        self.prefactor_2 = self.gamma_damping*(np.cumsum(sum_term)-sum_term)\n",
    "        \n",
    "    def init_matrices(self):\n",
    "\n",
    "        self.g_matrix = np.zeros((self.num_actions, self.num_percepts)) #glow matrix, for processing delayed rewards\n",
    "\n",
    "        # initialize h matrix with different values\n",
    "        if len(self.initial_prob_distr[0]) > 0:          \n",
    "            self.h_0 = self.initial_prob_distr\n",
    "            self.h_matrix = self.h_0.copy()\n",
    "        else: \n",
    "            self.h_matrix = np.ones((self.num_actions, self.num_percepts), dtype=np.float64) #Note: the first index specifies the action, the second index specifies the percept.\n",
    "            \n",
    "    def _learn_post_reward(self, reward):\n",
    "        if self.counter_upd == 0:\n",
    "            print('Counter for h_matrix is zero, check that your are properly updating it!')\n",
    "        if len(self.initial_prob_distr[0]) > 0:\n",
    "            self.h_matrix = self.prefactor_1[self.counter_upd ] * self.h_matrix + self.prefactor_2[self.counter_upd] * self.h_0 + reward * self.g_matrix\n",
    "        else:\n",
    "            self.h_matrix = self.prefactor_1[self.counter_upd ] * self.h_matrix + self.prefactor_2[self.counter_upd] + reward * self.g_matrix\n",
    "        self.counter_upd = 0\n",
    "        \n",
    "    def _hmat_upd_single_percept(self, t, percept):\n",
    "        if len(self.initial_prob_distr[0]) > 0:\n",
    "            return self.prefactor_1[t] * self.h_matrix[:, percept] + self.prefactor_2[t] * self.h_0[:, percept]\n",
    "        else:\n",
    "            return self.prefactor_1[t] * self.h_matrix[:, percept] + self.prefactor_2[t] \n",
    "            \n",
    "            \n",
    "    def percept_preprocess(self, observation):\n",
    "        \"\"\"\n",
    "        Takes a multi-feature percept and reduces it to a single integer index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : ARRAY of integers >=0, of the same length as self.num_percepts_list\n",
    "            List that describes the observation. Each entry is the value that each feature takes in the observation.\n",
    "            observation[i] < num_percepts_list[i] (strictly)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        percept : int\n",
    "            Percept index that corresponds to the input observation.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        percept = 0\n",
    "        for which_feature in range(len(observation)):\n",
    "            percept += int(observation[which_feature] * np.prod(self.num_percepts_list[:which_feature]))\n",
    "        return percept\n",
    "    \n",
    "    def deliberate(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation , this method chooses the next action and records that choice in the g_matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : list\n",
    "            List that describes the observation, as specified in percept_preprocess.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        action : int\n",
    "            Index of the chosen action.\n",
    "\n",
    "        \"\"\"\n",
    "        percept = self.percept_preprocess(observation) \n",
    "        \n",
    "        # Probabilities must be of update h_matrix. We feed the prob distr the update h_matrix\n",
    "        # for the percept, but don't update the h_matrix\n",
    "        current_h_mat = self._hmat_upd_single_percept(self.counter_upd, percept)\n",
    "        probs = self.probability_distr(percept, h_matrix = current_h_mat)\n",
    "        \n",
    "        action = rand_choice_nb(arr = np.arange(self.num_actions), prob = probs)\n",
    "        self.g_matrix = (1 - self.eta_glow_damping) * self.g_matrix\n",
    "        self.g_matrix[action, percept] += 1 #record latest decision in g_matrix\n",
    "        return action\n",
    "    \n",
    "    def probability_distr(self, percept, h_matrix = None):\n",
    "        \"\"\"\n",
    "        UPDATE (added the optional input)\n",
    "         \n",
    "        Given a percept index, this method returns a probability distribution over actions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        percept : int\n",
    "            Index of the given percept.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probability_distr : np.array, length = num_actions\n",
    "            Probability for each action (normalized to unit sum), computed according to policy_type.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.policy_type == 'standard':\n",
    "            h_vector = self.h_matrix[:, percept] if h_matrix is None else h_matrix\n",
    "            probability_distr = h_vector / np.sum(h_vector)\n",
    "        elif self.policy_type == 'softmax':\n",
    "            h_vector = self.beta_softmax * self.h_matrix[:, percept] if h_matrix is None else h_matrix\n",
    "            h_vector_mod = h_vector - np.max(h_vector)\n",
    "            probability_distr = np.exp(h_vector_mod) / np.sum(np.exp(h_vector_mod))\n",
    "        return probability_distr\n",
    "    \n",
    "    def learn(self, reward):\n",
    "        \"\"\"\n",
    "        Given a reward, this method updates the h matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reward : float\n",
    "            Value of the obtained reward.\n",
    "        \"\"\"\n",
    "        if len(self.initial_prob_distr[0]) > 0:\n",
    "            self.h_matrix =  self.h_matrix - self.gamma_damping * (self.h_matrix - self.h_0) + reward * self.g_matrix\n",
    "        else:\n",
    "            self.h_matrix =  self.h_matrix - self.gamma_damping * (self.h_matrix - 1.) + reward * self.g_matrix\n",
    "            \n",
    "    def reset_g(self):\n",
    "        \"\"\"\n",
    "        Resets the g_matrix.\n",
    "        \"\"\"\n",
    "        self.g_matrix = np.zeros((self.num_actions, self.num_percepts), dtype=np.float64)\n",
    "        \n",
    "    def deliberate_fixed_policy(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation , this method chooses the next action according to the fixed policy specified as attribute of the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : list\n",
    "            List that describes the observation, as specified in percept_preprocess.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        action : int\n",
    "            Index of the chosen action.\n",
    "\n",
    "        \"\"\"\n",
    "        percept = self.percept_preprocess(observation) \n",
    "        if len(self.fixed_policy[0]) > 0:\n",
    "            action = rand_choice_nb(arr = np.arange(self.num_actions), prob = self.fixed_policy[percept])\n",
    "        else:\n",
    "            print('No fixed policy was given to the agent. The action will be selected randomly.')\n",
    "            action = np.random.choice(self.num_actions)\n",
    "    \n",
    "        self.g_matrix = (1 - self.eta_glow_damping) * self.g_matrix\n",
    "        self.g_matrix[action, percept] += 1 #record latest decision in g_matrix\n",
    "    \n",
    "        return action\n",
    "    \n",
    "    def act(self, action):\n",
    "        \"\"\"\n",
    "        Agent performs the given action.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : int (0, 1)\n",
    "            1 if it changes direction, 0 otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # If the agent changes direction   \n",
    "        if action == 1:\n",
    "            self.agent_state = 0\n",
    "        else:\n",
    "            self.agent_state += 1  \n",
    "            \n",
    "    \n",
    "    def get_state(self):  \n",
    "        ''' simplified to case of single forager. Returns list because is what deliberate needs'''\n",
    "        return np.array([self.agent_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_train_loop_Heff(efficient, agent, episodes):\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        \n",
    "        if efficient:\n",
    "            agent.counter_upd += 1\n",
    "        \n",
    "        state = np.array([i])\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            action = 0\n",
    "        else: 1\n",
    "        \n",
    "        # here is where glow matrix updates:\n",
    "        agent.g_matrix = (1 - agent.eta_glow_damping) * agent.g_matrix\n",
    "        agent.g_matrix[action, i] += 1 #record latest decision in g_matrix\n",
    "        \n",
    "        if i == 2 or i == 6:\n",
    "            reward = 1\n",
    "        else: reward = 0\n",
    "        \n",
    "        if efficient:\n",
    "            if reward == 1:\n",
    "                agent._learn_post_reward(reward)\n",
    "                agent.counter_upd = 0\n",
    "        else:\n",
    "            agent.learn(reward)\n",
    "\n",
    "    if efficient:\n",
    "        agent._learn_post_reward(reward)\n",
    "            \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "**Value testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from rl_opts.rl_framework import Forager as Forager_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "eps = 10\n",
    "gamma_damping = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.90236435, 2.90236435, 2.90236435, 1.970299  , 1.970299  ,\n",
       "        1.970299  , 1.970299  , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "agent_noopt = Forager_classic(num_actions = 2,\n",
    "                              state_space = np.array([np.arange(eps)]),\n",
    "                              gamma_damping = gamma_damping)\n",
    "\n",
    "trained_noopt = test_train_loop_Heff(efficient = False, agent = agent_noopt, episodes = eps)\n",
    "trained_noopt.h_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.90236435, 2.90236435, 2.90236435, 1.970299  , 1.970299  ,\n",
       "        1.970299  , 1.970299  , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "agent_opt = _Forager_efficient_H(num_actions = 2,\n",
    "                                 state_space = np.array([np.arange(eps)]),\n",
    "                                 gamma_damping = gamma_damping)\n",
    "\n",
    "trained = test_train_loop_Heff(efficient=True, agent = agent_opt, episodes = eps)\n",
    "trained.h_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comparison old and efficient: -7.438494264988549e-15 ||||| IF value != 0, something is wrong!!!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "f'comparison old and efficient: {(trained.h_matrix-trained_noopt.h_matrix).sum()} ||||| IF value != 0, something is wrong!!!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "Manual testing: we define an h-matrix and let it damp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "eps = 10\n",
    "len_hmat = 5\n",
    "gamma_damping = 0.001\n",
    "rand_h = [[2.0,2,4,5,1],\n",
    "          [3,3,1,1,1]]\n",
    "rand_h = np.array(rand_h)\n",
    "\n",
    "\n",
    "#np.random.rand(2, len_hmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "agent_noopt = Forager_classic(num_actions = 2,\n",
    "                              state_space = np.array([np.arange(len_hmat)]),\n",
    "                              gamma_damping = gamma_damping)\n",
    "agent_noopt.h_matrix = rand_h.copy()\n",
    "\n",
    "for e in range(eps):\n",
    "    agent_noopt.learn(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99004488, 1.99004488, 3.97013464, 4.96017952, 1.        ],\n",
       "       [2.98008976, 2.98008976, 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "agent_noopt.h_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "agent_opt = _Forager_efficient_H(num_actions = 2,\n",
    "                                 state_space = np.array([np.arange(len_hmat)]),\n",
    "                                 gamma_damping = gamma_damping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99004488, 1.99004488, 3.97013464, 4.96017952, 1.        ],\n",
       "       [2.98008976, 2.98008976, 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "agent_opt.h_matrix = rand_h.copy()\n",
    "\n",
    "agent_opt.counter_upd = 10\n",
    "agent_opt._learn_post_reward(0)\n",
    "agent_opt.h_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forager \n",
    "This agent is an efficient version of rl_opts.rl_framework.Forager with:\n",
    "\n",
    "- `numba` implementation\n",
    "-  H and G matrix efficient updates (contribution by Michele Caraglio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@jitclass([(\"size_state_space\", int64[:]),           \n",
    "           (\"initial_prob_distr\", float64[:,:]),           \n",
    "           (\"fixed_policy\", float64[:,:]) ,\n",
    "           (\"h_matrix\", float64[:,:]) ,\n",
    "           (\"g_matrix\", float64[:,:]) ,\n",
    "           (\"h_0\", float64[:,:]),\n",
    "           (\"prefactor_1\", float64[:]),\n",
    "           (\"prefactor_2\", float64[:]),\n",
    "           (\"last_upd_G\", float64[:,:])\n",
    "          ])\n",
    "class Forager():\n",
    "    num_actions : int\n",
    "    gamma_damping : float\n",
    "    eta_glow_damping : float\n",
    "    policy_type : str\n",
    "    beta_softmax : float\n",
    "    num_percepts : int\n",
    "    agent_state : int\n",
    "    size_state_space : np.array\n",
    "    initial_prob_distr : np.array\n",
    "    fixed_policy : np.array    \n",
    "    h_matrix : np.array\n",
    "    g_matrix : np.array\n",
    "    h_0 : np.array\n",
    "    # Efficient H update\n",
    "    prefactor_1: np.array\n",
    "    prefactor_2: np.array\n",
    "    max_no_H_update : int\n",
    "    N_upd_H : int\n",
    "    # Efficient G update\n",
    "    last_upd_G: np.array\n",
    "    N_upd_G: int\n",
    "    \n",
    "    def __init__(self, num_actions, # Number of actions\n",
    "                 size_state_space, \n",
    "                 # List where each entry is the state space of each perceptual feature. \n",
    "                 # In general we only consider one perceptual feature (counter)\n",
    "                 gamma_damping=0.0, # Gamma of PS\n",
    "                 eta_glow_damping=0.0, # Glow of PS\n",
    "                 policy_type='standard', # Sampling of policy\n",
    "                 beta_softmax=3, # Parameters if policy is softmax\n",
    "                 initial_prob_distr = np.array([[],[]]), # Initial h-matrix\n",
    "                 fixed_policy=np.array([[],[]]), # If considering a fixed policy\n",
    "                 max_no_H_update = int(1e4) # maximum number of steps before an update of H and G matrices.\n",
    "                ):\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Updated version of the `rl_framework.Forager` class, with an efficient update both for the H-matrix and the G-matrix.\n",
    "\n",
    "        **Inputs**\n",
    "        \n",
    "        `num_actions` : \n",
    "            Number of actions\n",
    "            \n",
    "        `size_state_space` : \n",
    "             List where each entry is the state space of each perceptual feature. In general we only consider one perceptual feature (counter)\n",
    "        \n",
    "        `gamma_damping` :\n",
    "            Gamma of PS\n",
    "        \n",
    "        `eta_glow_damping` :\n",
    "            Glow of PS\n",
    "        \n",
    "        `policy_type` :\n",
    "            Sampling of policy\n",
    "        \n",
    "        `beta_softmax` :\n",
    "            Parameters if policy is softmax\n",
    "        \n",
    "        `initial_prob_distr` :\n",
    "            Initial h-matrix\n",
    "        \n",
    "        `fixed_policy` :\n",
    "            If considering a fixed policy\n",
    "        \n",
    "        `max_no_H_update` :\n",
    "            Maximum number of steps before an update of H and G matrices.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.agent_state = 0\n",
    "        \n",
    "        self.num_actions = num_actions\n",
    "        self.size_state_space = size_state_space\n",
    "        self.num_percepts = int(np.prod(self.size_state_space)) # total number of possible percepts\n",
    "        \n",
    "        self.gamma_damping = gamma_damping\n",
    "        self.eta_glow_damping = eta_glow_damping\n",
    "        self.policy_type = policy_type\n",
    "        self.beta_softmax = beta_softmax\n",
    "        self.initial_prob_distr = initial_prob_distr\n",
    "        self.fixed_policy = fixed_policy       \n",
    "        \n",
    "        self.init_matrices()\n",
    "        \n",
    "        # # For H update\n",
    "        self.max_no_H_update = max_no_H_update      \n",
    "        self.N_upd_H = 0\n",
    "        self.prefactor_1 = (1-self.gamma_damping)**(np.arange(self.max_no_H_update+1)) \n",
    "\n",
    "        # This is the slow / easy to understand way of computing prefactor_2\n",
    "        # self.prefactor_2 = np.zeros(self.max_no_H_update+1)       \n",
    "        # for i in range(self.max_no_H_update):\n",
    "        #     self.prefactor_2[i+1] = self.gamma_damping*np.sum((1-self.gamma_damping)**np.arange(i+1))\n",
    "        # and this it the efficient way\n",
    "        sum_term = (1-self.gamma_damping)**np.arange(self.max_no_H_update+1)\n",
    "        self.prefactor_2 = self.gamma_damping*(np.cumsum(sum_term)-sum_term)\n",
    "        \n",
    "        \n",
    "            \n",
    "        # For G update\n",
    "        self.last_upd_G = np.zeros((self.num_actions, self.num_percepts))\n",
    "        self.N_upd_G = 0\n",
    "                              \n",
    "        \n",
    "    def init_matrices(self):\n",
    "\n",
    "        self.g_matrix = np.zeros((self.num_actions, self.num_percepts)) #glow matrix, for processing delayed rewards\n",
    "\n",
    "        # initialize h matrix with different values\n",
    "        if len(self.initial_prob_distr[0]) > 0:          \n",
    "            self.h_0 = self.initial_prob_distr\n",
    "            self.h_matrix = self.h_0.copy()\n",
    "        else: \n",
    "            self.h_matrix = np.ones((self.num_actions, self.num_percepts), dtype=np.float64) #Note: the first index specifies the action, the second index specifies the percept.\n",
    "            \n",
    "    def _learn_post_reward(self, reward):\n",
    "        '''Given a reward, updates the whole H-matrix taking into account that we did not have updates\n",
    "        for the last N_upd_H steps.'''\n",
    "        # Update the full G matrix\n",
    "        self._G_upd_full()\n",
    "        \n",
    "        if self.N_upd_H == 0:\n",
    "            print('Counter for h_matrix is zero, check that your are properly updating it!')\n",
    "        if len(self.initial_prob_distr[0]) > 0:\n",
    "            self.h_matrix = self.prefactor_1[self.N_upd_H ] * self.h_matrix + self.prefactor_2[self.N_upd_H] * self.h_0 + reward * self.g_matrix\n",
    "        else:\n",
    "            self.h_matrix = self.prefactor_1[self.N_upd_H ] * self.h_matrix + self.prefactor_2[self.N_upd_H] + reward * self.g_matrix\n",
    "        self.N_upd_H = 0\n",
    "        \n",
    "    def _H_upd_single_percept(self, t, percept):\n",
    "        '''Given a percept and the time t passed since the last H-matrix update,\n",
    "        returns the corresponding --updated-- column of the H-matrix for all actions.\n",
    "        This updated is local and does no affect the H-matrix.'''\n",
    "        if len(self.initial_prob_distr[0]) > 0:\n",
    "            return self.prefactor_1[t] * self.h_matrix[:, percept] + self.prefactor_2[t] * self.h_0[:, percept]\n",
    "        else:\n",
    "            return self.prefactor_1[t] * self.h_matrix[:, percept] + self.prefactor_2[t] \n",
    "        \n",
    "    def _G_upd_single_percept(self, percept, action):\n",
    "        '''Given a percept-action tuple, updates that element of the G-matrix. Updates the last_upd_G\n",
    "        to keep track of when was the matrix updated.'''\n",
    "        # For the current (a,s) tuple, we damp and sum one\n",
    "        self.g_matrix[action, percept] = (1 - self.eta_glow_damping)**(self.N_upd_G - self.last_upd_G[action, percept])*self.g_matrix[action, percept] + 1\n",
    "        # Then update the last_upd matrix\n",
    "        self.last_upd_G[action, percept] = self.N_upd_G\n",
    "        \n",
    "    def _G_upd_full(self):\n",
    "        '''Given the current number of steps without an update, updates the whole G-matrix.\n",
    "        Then, resets all counters.'''\n",
    "        self.g_matrix = (1 - self.eta_glow_damping)**(self.N_upd_G - self.last_upd_G) * self.g_matrix\n",
    "        self.N_upd_G = 0\n",
    "        self.last_upd_G = np.zeros((self.num_actions, self.num_percepts))\n",
    "            \n",
    "            \n",
    "    def percept_preprocess(self, observation):\n",
    "        \"\"\"\n",
    "        Takes a multi-feature percept and reduces it to a single integer index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : ARRAY of integers >=0, of the same length as self.num_percepts_list\n",
    "            List that describes the observation. Each entry is the value that each feature takes in the observation.\n",
    "            observation[i] < num_percepts_list[i] (strictly)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        percept : int\n",
    "            Percept index that corresponds to the input observation.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        percept = 0\n",
    "        for idx_obs, obs_feature in enumerate(observation):\n",
    "            percept += int(obs_feature * np.prod(self.size_state_space[:idx_obs]))  \n",
    "        return percept\n",
    "    \n",
    "    def deliberate(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation , this method chooses the next action and records that choice in the g_matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : list\n",
    "            List that describes the observation, as specified in percept_preprocess.\n",
    "        action : optional, bool\n",
    "            Mostly for debugging, we can input the action and no deliberation takes place, but g_matrix is updated\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        action : int\n",
    "            Index of the chosen action.\n",
    "\n",
    "        \"\"\"\n",
    "        percept = self.percept_preprocess(observation) \n",
    "        \n",
    "        \n",
    "        # Probabilities must be of update h_matrix. We feed the prob distr the update h_matrix\n",
    "        # for the percept, but don't update the h_matrix\n",
    "        current_h_mat = self._H_upd_single_percept(self.N_upd_H, percept)\n",
    "        probs = self.probability_distr(percept, h_matrix = current_h_mat)        \n",
    "        action = rand_choice_nb(arr = np.arange(self.num_actions), prob = probs)\n",
    "        \n",
    "        # Update the G matrix for current (s,a) tuple\n",
    "        self._G_upd_single_percept(percept, action)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def probability_distr(self, percept, h_matrix = None):\n",
    "        \"\"\"\n",
    "        UPDATE (added the optional input)\n",
    "         \n",
    "        Given a percept index, this method returns a probability distribution over actions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        percept : int\n",
    "            Index of the given percept.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probability_distr : np.array, length = num_actions\n",
    "            Probability for each action (normalized to unit sum), computed according to policy_type.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.policy_type == 'standard':\n",
    "            h_vector = self.h_matrix[:, percept] if h_matrix is None else h_matrix\n",
    "            probability_distr = h_vector / np.sum(h_vector)\n",
    "        elif self.policy_type == 'softmax':\n",
    "            h_vector = self.beta_softmax * self.h_matrix[:, percept] if h_matrix is None else h_matrix\n",
    "            h_vector_mod = h_vector - np.max(h_vector)\n",
    "            probability_distr = np.exp(h_vector_mod) / np.sum(np.exp(h_vector_mod))\n",
    "        return probability_distr\n",
    "    \n",
    "    def learn(self, reward):\n",
    "        \"\"\"\n",
    "        Given a reward, this method updates the h matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reward : float\n",
    "            Value of the obtained reward.\n",
    "        \"\"\"\n",
    "        if len(self.initial_prob_distr[0]) > 0:\n",
    "            self.h_matrix =  self.h_matrix - self.gamma_damping * (self.h_matrix - self.h_0) + reward * self.g_matrix\n",
    "        else:\n",
    "            self.h_matrix =  self.h_matrix - self.gamma_damping * (self.h_matrix - 1.) + reward * self.g_matrix\n",
    "            \n",
    "    def reset_g(self):\n",
    "        \"\"\"\n",
    "        Resets the g_matrix.\n",
    "        \"\"\"\n",
    "        self.g_matrix = np.zeros((self.num_actions, self.num_percepts), dtype=np.float64)\n",
    "        \n",
    "    def deliberate_fixed_policy(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation , this method chooses the next action according to the fixed policy specified as attribute of the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : list\n",
    "            List that describes the observation, as specified in percept_preprocess.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        action : int\n",
    "            Index of the chosen action.\n",
    "\n",
    "        \"\"\"\n",
    "        percept = self.percept_preprocess(observation) \n",
    "        if len(self.fixed_policy[0]) > 0:\n",
    "            action = rand_choice_nb(arr = np.arange(self.num_actions), prob = self.fixed_policy[percept])\n",
    "        else:\n",
    "            print('No fixed policy was given to the agent. The action will be selected randomly.')\n",
    "            action = np.random.choice(self.num_actions)\n",
    "    \n",
    "        self.g_matrix = (1 - self.eta_glow_damping) * self.g_matrix\n",
    "        self.g_matrix[action, percept] += 1 #record latest decision in g_matrix\n",
    "    \n",
    "        return action\n",
    "    \n",
    "    def act(self, action):\n",
    "        \"\"\"\n",
    "        Agent performs the given action.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : int (0, 1)\n",
    "            1 if it changes direction, 0 otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # If the agent changes direction   \n",
    "        if action == 1:\n",
    "            self.agent_state = 0\n",
    "        else:\n",
    "            self.agent_state += 1  \n",
    "            \n",
    "    \n",
    "    def get_state(self):  \n",
    "        ''' simplified to case of single forager. Returns list because is what deliberate needs'''\n",
    "        return np.array([self.agent_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# @jit\n",
    "def test_train_loop(efficient, agent, episodes):\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        \n",
    "        if efficient:\n",
    "            agent.N_upd_H += 1\n",
    "            agent.N_upd_G += 1\n",
    "        \n",
    "        state = np.array([i])\n",
    "        \n",
    "        # Do determinist action to keep track\n",
    "        if i % 2 == 0:\n",
    "            action = 0\n",
    "        else: action = 1       \n",
    "        \n",
    "        # Because deterministic action, do update of G matrix by hand copying what is in agent.deliberate\n",
    "        agent.deliberate(state)\n",
    "        \n",
    "        if i == 2 or i == 6:\n",
    "            reward = 1\n",
    "        else: reward = 0\n",
    "        \n",
    "        if efficient:\n",
    "            if reward == 1:\n",
    "                agent._learn_post_reward(reward)\n",
    "        else:\n",
    "            agent.learn(reward)\n",
    "    \n",
    "    if efficient:\n",
    "        agent._learn_post_reward(reward)\n",
    "\n",
    "    \n",
    "            \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value testing**\n",
    "\n",
    "Because actions are random, the row of the value will change. But in each column, you should have consistent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_opts.rl_framework import Forager as Forager_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.91, 0.  , 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.  , 1.  ],\n",
       "        [0.  , 0.92, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  ]]),\n",
       " array([[2.91192, 1.     , 2.95074, 1.96739, 1.97716, 1.98703, 1.997  ,\n",
       "         1.     , 1.     , 1.     ],\n",
       "        [1.     , 2.93123, 1.     , 1.     , 1.     , 1.     , 1.     ,\n",
       "         1.     , 1.     , 1.     ]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 10\n",
    "agent_noopt = Forager_classic(num_actions = 2,\n",
    "                              state_space = np.array([np.arange(eps)]), eta_glow_damping = 0.01, gamma_damping = 0.001)\n",
    "trained_noopt = test_train_loop(efficient = False, agent = agent_noopt, episodes = eps)\n",
    "trained_noopt.g_matrix.round(2), trained_noopt.h_matrix.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.  , 0.92, 0.  , 0.  , 0.  , 0.96, 0.  , 0.98, 0.99, 0.  ],\n",
       "        [0.91, 0.  , 0.93, 0.94, 0.95, 0.  , 0.97, 0.  , 0.  , 1.  ]]),\n",
       " array([[1.     , 2.93123, 1.     , 1.     , 1.     , 1.98703, 1.     ,\n",
       "         1.     , 1.     , 1.     ],\n",
       "        [2.91192, 1.     , 2.95074, 1.96739, 1.97716, 1.     , 1.997  ,\n",
       "         1.     , 1.     , 1.     ]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_opt = Forager(num_actions = 2,\n",
    "                    size_state_space = np.array([eps]), eta_glow_damping = 0.01, gamma_damping = 0.001)\n",
    "trained = test_train_loop(efficient=True, agent = agent_opt, episodes = eps)\n",
    "\n",
    "trained.g_matrix.round(2), trained.h_matrix.round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Runtime testing only H vs. full efficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = int(1e4); eta = 0.1\n",
    "agent_noopt = _Forager_original(num_actions = 2,\n",
    "                                state_space = np.array([np.arange(eps)]), \n",
    "                                eta_glow_damping = eta)\n",
    "agent_opt = Forager(num_actions = 2,\n",
    "                    size_state_space = np.array([eps]), \n",
    "                    eta_glow_damping = eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.6 ms ± 122 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_train_loop(efficient=True, agent = agent_opt, episodes = eps)\n",
    "# Runtime new Forager (efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 ms ± 32.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_train_loop(efficient=False, agent = agent_noopt, episodes = eps)\n",
    "# Runtime old Forager "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch multi agent learning\n",
    "We now make use of the parallel option of `numba` to create launchers where many agents are trained at the same time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "@jit(nopython = NOPYTHON)\n",
    "def _train_loop_original(episodes, # Number of episodes to train\n",
    "               time_ep, # Length of episode\n",
    "               agent, # Agent class\n",
    "               env # Environment class\n",
    "              ): # Rewards in each episode and time step and h_matrix of the trained agent \n",
    "    '''\n",
    "    Training loop for _Forager_original.\n",
    "    '''\n",
    "    \n",
    "    save_rewards = np.zeros((episodes, time_ep))\n",
    "    \n",
    "    for ep in range(episodes):\n",
    "        # print(f'starting episode {ep} for agent {n_agent}')\n",
    "        #initialize environment and agent's counter and g matrix\n",
    "        env.init_env()\n",
    "        agent.agent_state = 0\n",
    "        agent.reset_g()\n",
    "\n",
    "        for t in range(time_ep):\n",
    "\n",
    "            #step to set counter to its min value n=1\n",
    "            if t == 0 or env.kicked[0]:\n",
    "                #do one step with random direction (no learning in this step)\n",
    "                env.update_pos(1)\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                #reset counter\n",
    "                agent.agent_state = 0\n",
    "                #set kicked value to false again\n",
    "                env.kicked[0] = 0\n",
    "                reward = 0\n",
    "\n",
    "            else:\n",
    "                #get perception\n",
    "                state = agent.get_state()\n",
    "                #decide\n",
    "                action = agent.deliberate(state)\n",
    "                #act (update counter)\n",
    "                agent.act(action)\n",
    "\n",
    "                #update positions\n",
    "                env.update_pos(action)\n",
    "                #check if target was found + kick if it is\n",
    "                reward = env.check_encounter()\n",
    "\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                #learn\n",
    "\n",
    "                agent.learn(reward)                \n",
    "                    \n",
    "            save_rewards[ep, t] = reward\n",
    "      \n",
    "    \n",
    "    return save_rewards, agent.h_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "@jit(nopython = NOPYTHON)\n",
    "def _train_loop_h_efficient(episodes, time_ep, agent, env, h_mat_allT = False):  \n",
    "    '''\n",
    "    Training loop for _Forager_h_efficient.\n",
    "    '''\n",
    "\n",
    "    if h_mat_allT: policy_t = np.zeros((episodes, agent.h_matrix.shape[-1]))\n",
    "    save_rewards = np.zeros((episodes, time_ep))\n",
    "    \n",
    "    for ep in range(episodes):\n",
    "        # print(f'starting episode {ep} for agent {n_agent}')\n",
    "        #initialize environment and agent's counter and g matrix\n",
    "        env.init_env()\n",
    "        agent.agent_state = 0\n",
    "        agent.reset_g()\n",
    "\n",
    "        for t in range(time_ep):\n",
    "            agent.counter_upd += 1\n",
    "            \n",
    "            #step to set counter to its min value n=1\n",
    "            if t == 0 or env.kicked[0]:\n",
    "                #do one step with random direction (no learning in this step)\n",
    "                env.update_pos(1)\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                #reset counter\n",
    "                agent.agent_state = 0\n",
    "                #set kicked value to false again\n",
    "                env.kicked[0] = 0\n",
    "                reward = 0\n",
    "\n",
    "            else:\n",
    "                #get perception\n",
    "                state = agent.get_state()\n",
    "                #decide\n",
    "                action = agent.deliberate(state)\n",
    "                #act (update counter)\n",
    "                agent.act(action)\n",
    "\n",
    "                #update positions\n",
    "                env.update_pos(action)\n",
    "                #check if target was found + kick if it is\n",
    "                reward = env.check_encounter()\n",
    "\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                #learn\n",
    "                if reward == 1 or agent.counter_upd > agent.max_no_update:\n",
    "                    agent._learn_post_reward(reward)\n",
    "                    \n",
    "            # Saving\n",
    "            save_rewards[ep, t] = reward\n",
    "            if h_mat_allT: policy_t[ep] = agent.h_matrix[0,:] / agent.h_matrix.sum(0)\n",
    "      \n",
    "    return (save_rewards, policy_t) if h_mat_allT else (save_rewards, agent.h_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "@jit(nopython = NOPYTHON)\n",
    "def train_loop(episodes : int, # Number of episodes to train\n",
    "               time_ep : int, # Length of episode\n",
    "               agent : object, # Agent class\n",
    "               env : object, # Environment class\n",
    "               h_mat_allT : bool = False # If True, returns the h_matrix at all times\n",
    "              )-> tuple: # Rewards and h-matrix of the trained agent      \n",
    "    '''    \n",
    "    Given an agent and environment, performs a loop train for the `TargetEnv` type of environment, by adequatly\n",
    "    updating the H and G counters, considering boundaries, etc... \n",
    "    '''\n",
    "\n",
    "    if h_mat_allT: policy_t = np.zeros((episodes, agent.h_matrix.shape[-1]))\n",
    "    save_rewards = np.zeros((episodes, time_ep))\n",
    "    \n",
    "    for ep in range(episodes):\n",
    "        # print(f'starting episode {ep} for agent {n_agent}')\n",
    "        #initialize environment and agent's counter and g matrix\n",
    "        env.init_env()\n",
    "        agent.agent_state = 0\n",
    "        agent.reset_g()\n",
    "\n",
    "        for t in range(time_ep):\n",
    "            agent.N_upd_H += 1\n",
    "            agent.N_upd_G += 1\n",
    "            \n",
    "            #step to set counter to its min value n=1\n",
    "            if t == 0 or env.kicked[0]:\n",
    "                #do one step with random direction (no learning in this step)\n",
    "                env.update_pos(1)\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                #reset counter\n",
    "                agent.agent_state = 0\n",
    "                #set kicked value to false again\n",
    "                env.kicked[0] = 0\n",
    "                reward = 0\n",
    "\n",
    "            else:\n",
    "                #get perception\n",
    "                state = agent.get_state()\n",
    "                #decide\n",
    "                action = agent.deliberate(state)\n",
    "                #act (update counter)\n",
    "                agent.act(action)\n",
    "\n",
    "                #update positions\n",
    "                env.update_pos(action)\n",
    "                #check if target was found + kick if it is\n",
    "                reward = env.check_encounter()\n",
    "\n",
    "                #check boundary conditions\n",
    "                env.check_bc()\n",
    "                #learn\n",
    "                if reward == 1:\n",
    "                    agent._learn_post_reward(reward)\n",
    "\n",
    "            if agent.N_upd_H == agent.max_no_H_update-1:\n",
    "                agent._learn_post_reward(reward)\n",
    "\n",
    "            # Saving\n",
    "            save_rewards[ep, t] = reward\n",
    "            \n",
    "        if h_mat_allT: policy_t[ep] = agent.h_matrix[0,:] / agent.h_matrix.sum(0)\n",
    "      \n",
    "    return (save_rewards, policy_t) if h_mat_allT else (save_rewards, agent.h_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Runtime testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TargetEnv(Nt = 100,\n",
    "               L = 100, \n",
    "               r = 0.5, \n",
    "               lc = np.array([[1.0],[1]]), \n",
    "               agent_step = 1, \n",
    "               destructive = False, \n",
    "               lc_distribution = 'constant')\n",
    "\n",
    "\n",
    "agent = Forager(num_actions = 2, # From here are props of the agent (see Forager for details)\n",
    "               size_state_space = np.array([100]))\n",
    "\n",
    "agent_nopt = _Forager_original(num_actions = 2, # From here are props of the agent (see Forager for details)\n",
    "                     state_space = np.array([np.arange(100)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.7 ms ± 18.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _train_loop_original(episodes = 100, time_ep = 100, agent = agent_nopt, env = env)\n",
    "# Runtime without h-matrix efficient update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ms ± 57.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_loop(episodes = 100, time_ep = 100, agent = agent, env = env)\n",
    "# Runtime with h-matrix efficient update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run multiple agents in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@jit(nopython = NOPYTHON, parallel = True)\n",
    "def run_agents(episodes, # Number of episodes\n",
    "               time_ep, # Length of episode\n",
    "               N_agents, # Number of agents               \n",
    "               h_mat_allT = False, # If to save the h_matrix at all times\n",
    "               efficient_agent = True, # If to consider efficient H and G agent (other options: 'only H' or False)\n",
    "               Nt = 100, # From here are props of the environment (see TargetEnv for details) \n",
    "               L = 100, \n",
    "               r = 0.5, \n",
    "               lc = np.array([[1.0],[1]]), \n",
    "               agent_step = 1, \n",
    "               destructive_targets = False, \n",
    "               lc_distribution = 'constant', \n",
    "               num_actions = 2, # From here are props of the agent (see Forager for details)\n",
    "               size_state_space = np.array([100]), \n",
    "               gamma_damping = 0.00001,\n",
    "               eta_glow_damping = 0.1,\n",
    "               initial_prob_distr = np.array([[],[]]),\n",
    "               policy_type = 'standard', \n",
    "               beta_softmax = 3,  \n",
    "               fixed_policy = np.array([[],[]]),\n",
    "               max_no_H_update = int(1e3) \n",
    "              ):\n",
    "    \n",
    "    save_rewards = np.zeros((N_agents, episodes))\n",
    "    if h_mat_allT:\n",
    "        save_h_matrix = np.zeros((N_agents, episodes, size_state_space[0]))  \n",
    "    else:        \n",
    "        save_h_matrix = np.zeros((N_agents, 2, size_state_space[0])) \n",
    "    \n",
    "    for n_agent in prange(N_agents):\n",
    "        \n",
    "        env = TargetEnv(Nt,L,r,lc,agent_step,1,destructive_targets,lc_distribution)\n",
    "\n",
    "\n",
    "        if efficient_agent == True: # Both G and H efficient update\n",
    "            agent = Forager(num_actions,size_state_space,gamma_damping,\n",
    "                            eta_glow_damping,policy_type,beta_softmax,\n",
    "                            initial_prob_distr,fixed_policy,max_no_H_update)\n",
    "            rews, mat = train_loop(episodes, time_ep, agent, env, h_mat_allT) \n",
    "        \n",
    "        elif efficient_agent == 'only H': # Only H efficient update\n",
    "            state_space = np.arange(size_state_space[0]).reshape(1, size_state_space[0])\n",
    "            agent = _Forager_efficient_H(num_actions,state_space,gamma_damping,\n",
    "                                        eta_glow_damping,policy_type,beta_softmax,\n",
    "                                        initial_prob_distr,fixed_policy,max_no_H_update)\n",
    "            rews, mat = _train_loop_h_efficient(episodes, time_ep, agent, env, h_mat_allT)  \n",
    "            \n",
    "        elif efficient_agent == False: # Old version without efficient updates            \n",
    "            state_space = np.arange(size_state_space[0]).reshape(1, size_state_space[0])\n",
    "            agent = _Forager_original(num_actions,state_space,gamma_damping,\n",
    "                            eta_glow_damping,policy_type,beta_softmax,\n",
    "                            initial_prob_distr,fixed_policy)\n",
    "            rews, mat = _train_loop_original(episodes, time_ep, agent, env)    \n",
    "    \n",
    "        for t in range(episodes):\n",
    "            save_rewards[n_agent, t] = np.mean(rews[t])\n",
    "        save_h_matrix[n_agent] = mat\n",
    "        \n",
    "    return save_rewards, save_h_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Runtime testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorka/miniconda3/envs/rl_opts_main/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# For compiling and checking\n",
    "time_ep = 12000\n",
    "run_agents(episodes = 10, time_ep = time_ep, N_agents = 5, efficient_agent=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.26 s ± 35.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_agents(episodes = 100, time_ep = time_ep, N_agents = 10, size_state_space = np.array([100]), efficient_agent=False)\n",
    "# Runtime original in numba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.66 s ± 11.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit k = run_agents(episodes = 100, time_ep = time_ep, N_agents = 10, size_state_space = np.array([100]), efficient_agent='only H')\n",
    "# Runtime original with only H efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.66 s ± 20.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit k = run_agents(episodes = 100, time_ep = time_ep, N_agents = 10, size_state_space = np.array([100]), efficient_agent=True)\n",
    "# Runtime original with full H and G efficient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual environment \n",
    "This is a wrapper that merges the forager and agent whose only input is the displacement of a real particle at each step. The output is the action to be taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment:\n",
    "\n",
    "Just TargetEnv with `Nt = 1` and destructive targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_opts.numba.rl_framework import TargetEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = TargetEnv(Nt = 1, L = 5, destructive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = int(1e2)\n",
    "pos = np.zeros((2, T))\n",
    "\n",
    "env.init_env()\n",
    "env.positions[0] = np.array([env.L/2, env.L/2])\n",
    "for t in range(T):\n",
    "    env.update_pos_disp(np.random.randn(2)*0.3)\n",
    "    env.check_encounter()\n",
    "    #check boundary conditions\n",
    "    env.check_bc()\n",
    "\n",
    "    \n",
    "    \n",
    "    pos[:, t] = env.positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pos[0], pos[1])\n",
    "plt.xlim(0,env.L); plt.ylim(0,env.L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_opts.numba.rl_framework import Forager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Forager("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jitclass\n",
    "class virtual_wrapper:\n",
    "\n",
    "\n",
    "    def __init__(self, \n",
    "                 # Environment arguments\n",
    "                 Nt = 1, \n",
    "                 L = 5,\n",
    "                 r = 1,\n",
    "                 destructive = True,                 \n",
    "                 lc = np.array([[1.0],[1]]), # Won't enter into effect if destructive = True\n",
    "                 lc_distribution = 'constant', # Won't enter into effect if destructive = True\n",
    "                 agent_step = 1, # Won't enter into effect if position is updated with displacements\n",
    "                 # Agent arguments\n",
    "                 num_actions = 2, # Number of actions\n",
    "                 size_state_space = np.array([100]), \n",
    "                 # List where each entry is the state space of each perceptual feature. \n",
    "                 # In general we only consider one perceptual feature (counter)\n",
    "                 gamma_damping=0.0, # Gamma of PS\n",
    "                 eta_glow_damping=0.0, # Glow of PS\n",
    "                 policy_type='standard', # Sampling of policy\n",
    "                 beta_softmax=3, # Parameters if policy is softmax\n",
    "                 initial_prob_distr = np.array([[],[]]), # Initial h-matrix\n",
    "                 fixed_policy=np.array([[],[]]), # If considering a fixed policy\n",
    "                 max_no_H_update = int(1e4) # maximum number of steps before an update of H and G matrices.\n",
    "                 ):\n",
    "        \n",
    "        self.env = TargetEnv(Nt,L,r,lc,agent_step,1,destructive,lc_distribution)\n",
    "\n",
    "        self.agent = Forager(num_actions,size_state_space,gamma_damping,\n",
    "                             eta_glow_damping,policy_type,beta_softmax,\n",
    "                             initial_prob_distr,fixed_policy,max_no_H_update)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "VW = virtual_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "VW.env.init_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = int(1e2)\n",
    "pos = np.zeros((2, T))\n",
    "\n",
    "VW.env.init_env()\n",
    "VW.env.positions[0] = np.array([env.L/2, env.L/2])\n",
    "for t in range(T):\n",
    "    VW.env.update_pos_disp(np.random.randn(2)*0.3)\n",
    "    VW.env.check_encounter()\n",
    "    #check boundary conditions\n",
    "    VW.env.check_bc()\n",
    "\n",
    "    \n",
    "    \n",
    "    pos[:, t] = VW.env.positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGiCAYAAAChyG+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACSxklEQVR4nOzddXiT59fA8W+SuqXuClTQllLcZcoYGwwYE+bK3N3eufsGs9/GNqbYfMNdSikUaSm01N01beT9I22gtEBbUuV8rotrS/rkyZ027XNy3+c+R2EwGAwIIYQQQnQAZVcPQAghhBC9lwQaQgghhOgwEmgIIYQQosNIoCGEEEKIDiOBhhBCCCE6jAQaQgghhOgwEmgIIYQQosNIoCGEEEKIDiOBhhBCCCE6jAQaQgghhOgwbQo0nnvuORQKRZN/ERERHTU2IYQQQvRwFm19wMCBA1m9evXxE1i0+RRCCCGEOEe0OUqwsLDA29u7I8YihBBCiF6mzYFGcnIyvr6+2NjYMHr0aF555RUCAwNPebxGo0Gj0Zhu6/V6iouLcXNzQ6FQtG/UQgghhOhUBoOBiooKfH19USpbn3mhaEub+L/++ovKykrCw8PJycnh+eefJysri/379+Po6NjiY5577jmef/75Vg9ICCGEEN1XRkYG/v7+rT6+TYHGyUpLSwkKCuLtt9/mpptuavGYk2c0ysrKCAwMJCMjAycnp/Y+tRBCCCE6UXl5OQEBAZSWlqJWq1v9uLPK5HR2diYsLIwjR46c8hhra2usra2b3e/k5CSBhhBCCNHDtDXt4azqaFRWVnL06FF8fHzO5jRCCCGE6KXaFGg89NBDbNiwgWPHjrF161Yuv/xyVCoV8+fP76jxCSGEEKIHa9PSSWZmJvPnz6eoqAgPDw/GjRvH9u3b8fDw6KjxCSGEEKIHa1Og8cMPP3TUOIQQQgjRC0mvEyGEEEJ0GAk0hBBCCNFhJNAQQgghRIeRQEMIIYQQHUYCDSGEEEJ0GAk0hBBCCNFhJNAQQgghRIeRQEMIIYQQHUYCDSGEEEJ0GAk0hBBCCNFhJNAQQgghRIeRQEMIIYQQHUYCDSGEEEJ0GAk0hBBCCNFhJNAQQgghRIeRQEMIIYQQHUYCDSGEEEJ0GAk0hBBCCNFhLLp6AEIIIUR7fbk5lfTiaiID1ET6OxPibo9CoejqYYkTSKAhhBCiR0rMLeeF3w82uc/JxoLIAGeiGv5FBjjj7mDdRSMUIIGGEEKIHurfA3kABLvZ4Wpvxf7scsprtWxKLmRTcqHpOD9nW6ICnYnyNwYeg/3U2FqpumrY5xwJNIQQQvQodVo9H68/wkfrjgBw28S+zB8RSJ1WT1JuBfGZpezNKCU+o5SjBZVkldaQVVrDH/tyAFApFYR5ORIVoDbNeoR6OqJSypJLR1AYDAZDZz5heXk5arWasrIynJycOvOphRBC9HD7s8p46Oe9JOZWAHDBQC/enz8Ua4uWZyjKa+vZn1nGnozjwUd+habZcXZWKgb7HQ88ogKc8VHbSL7HCdp7/ZZAQwghRLen0ep4f00yn25IQac34GJnyfMzBzFjiE+bg4GcspqGoKOM+IwSEjLLqKrTNTvOw9GaSH9nhgY6E+nvzJAANU42luZ6ST2OBBpCCCF6pT3pJTzyyz6S8ysBmD7Yh+dnDjRbkqdOb+BoQSXx6aWmZZfE3Ap0+qaXRxtLJc9fOpB5wwPN8rw9jQQaQgghepXaeh1v/3eYzzeloDeAu4MV/zdzEBcN9unw566p03Egu4z4huWWPemlZJXWAHDNqECeuWQgVhbnVikqCTSEEEL0GrHHinnkl32kFFYBcFmUL8/OGIiLvVWXjEevN/DhuiO8s/owBgMMD3bho6uj8XS06ZLxdAUJNIQQQvR41XVaXv87ia+3HcNgAC8na166bDDTBnh19dAAWHMoj/t+iKdCo8XLyZpPrxnG0ECXrh5Wp5BAQwghRI9VW6/j34N5vPlPEunF1QDMjfHnyekDUNt2rwTMlIJKbl2ymyP5lViplPzfZedG3oYEGkIIIXoUg8HArmMlLIvL5I99OVRotAD4qm14ZfYQJoZ5dPEIT61So+XBn+L5p6Fo2LmQtyGBhhBCiB4hraiKZXFZLNuTSUZxjel+P2dbZkf7ccuEPjj2gG2ker2Bj9cf4a3/jHkbMUEufHxN783bkEBDCCFEt1VWU88f+3JYFpdJbFqJ6X57KxUXD/ZhVrQ/I0NcUfbA6pxrE/O494d4Kmp7d96GBBpCCCG6lXqdnk3JBfwal8V/B/Oo0+oBUCpgbD93rhjmz/kDvHtF35HUwipu/SaW5Ia8jV/uGM0Qf+euHpZZtff6Lb1OhBBCmI3BYOBAdjnL4rJYtTeLwso609fCvByYHe3PzCg/vNW9a3khxN2e5QvHcv2XO4lNK2H1wbxeF2i0lwQaQgghzlpeeS0r47P4dXcWSXkVpvvd7K24NMqX2dH+DPR16tW9QxysLRga6ExsWgkanb6rh9NtSKAhhBCiXWrqdPx7MJdf47LYnFxAY8VuK5WS8wZ4MSvajwlhHliqeu9OjJM17jppXCYSEmgIIYRoA73ewM5jxSyLy+TPhFwqG7akAgwLcmFWtB+XDPZFbdf9d410BCuVMd9EI4GGiQQaQgghziiloJLle7JYFpdl6vkB4O9iy6xof2YN9SPY3b4LR9g9yIxGcxJoCCGEaFFpdR2/N2xJjUsvNd3vYG3B9ME+zB7mT0yQS4/cktpRrCXQaEYCDSGEECb1Oj3rkwpYFpfJmkP51OmOb0mdEObBrGh/zh/ghY1lz9+S2hEaZzQ0Wl0Xj6T7kEBDCCHOcQaDgf1Z5fwal8mqvdkUVx3fkhrh7diwJdUXT6fetSW1I8jSSXMSaAghxDkqt6y2Ie8ik+T8StP97g7WXBbly6xofwb4SmHFtjAtncj2VhMJNIQQ4hxSXaflnwO5LIvLYvORQhprQ1tZKDl/gBezo/0ZH+qOxTm0JdWcJEejOQk0hBCil9PrDWxPKeLXuCz+2p9Ddd3x/IHhwS7MjvbnosE+3a4de090PEdDAo1GEmgIIUQvVlpdx9xF2zicd3xpJNDVjlnRflw+1I8gN9mSak6NdTRkRuM4mRsTQoherLpOR2ZJTZP7auqN9+3LLKO0uu4UjxTtIcmgzcmMhhBC9GK+zraseXAiqw/lsyEpn61Hiyio0PDL7kx+2Z2JUgFRAc5MCvdkYpgHg/3UUhfjLFjL0kkzEmgIIUQv56O25dpRQVw7KgiNVkfssRI2HC5gfVI+h/MqiUsvJS69lLf/O4yrvRUTQt2ZFO7J+FB33Bysu3r4PYrkaDQngYYQQpxDrC1UjO3nzth+7jxxcX+yS2vYcLiADUkFbDlSSHFVHSvis1kRn41CAUP81EwM82BiuCdRAc6oevhsR3ZpDYs3pjCqjysXDvIx+/mPL51Iwa5GEmgIIcQ5zNfZlvkjApk/IpB6nZ64tBLWNwQeB3PK2ZtZxt7MMt5fewS1rSXjQ90bAg8PPB17TgEvg8HAL7szeeG3g1RotBzJr+yYQEMldTROJoGGEEIIACxVSkb2cWNkHzcevTCC/PJa4xLL4QI2HS6grKae3/fl8Pu+HAAG+DgxKdyDiWEeRAe5dNt28HnltTyxLIE1ifmm+24cF9whz2VteTwZ1GAwoFD07Bkgc5BAQwghRIs8nWyYExPAnJgAtDo9ezNL2ZBkDDz2ZZZxMKecgznlfLz+KI7WFozt524MPMI98FHbdvXwMRgMrIzP5tlVByirqTfdf2mkL1MivDrkOa0btrfqDaDVG7BUSaAhgYYQQogzslApGRbkyrAgVx44P5zCSg2bko1LLBuTjbkdfx/I5e8DuQCEezkyMdyDSWEeDAt2wdqic5uwFVRoeGpFAv8cyGtyv4udJc/OGNBhz9uYowHGWY3uOsvTmSTQEEII0WbuDtZcPtSfy4f6o9Mb2J9VxvqkAjYczic+o5SkvAqS8ipYvDEFOysVY/q6mwKPAFe7Dh3b7/uyeXrFfkqq67FUKZg+2IdVe7PRG+DZGQM7dCfNyYGGvWzakUBDCCHE2VEpFUQGOBMZ4My900Ipqapj85HChsCjgMJKDasP5bH6kHF2oY+HPZPCPJkY7sHIEFeztZwvrqrj6ZX7+aMhh6S/jxNvXDGEZ1cdQG+AyeEezIzyNctznYpKqcBCqUCrN0hCaAMJNIQQQpiVi70VMyJ9mRHpi15v4GBOuWkL7e70ElIKqkgpSOXLLanYWCoZ1ceNSQ1baEPc21cS/Z8DuTy5PIHCyjpUSgULJ/fjrsn9WLoznd1pJdhbqXjx8sGdkpxpZaFEW6dDUy+BBkigIYQQogMplQoG+akZ5Kdm4eR+lNXUs/WE2Y7c8lrWJxWwPqkAfjtIkJtdQ9Dhweg+7thanX62o7S6judWHWBFfDYAYV4OvDUnisH+ajJLqnn970QAHr0oAj/nzklQtbJQUl2no04ntTRAAg0hhBCdSG1ryUWDfbhosA8Gg4HDeZWsT8pnw+ECdh0rJq2omq+3pfH1tjSsLJSMDHFlYpgHk8I96Ovh0GRGYs2hPB5blkBBhQalAm6f2Jd7p4VibaHCYDDw5PL9VNXpiAly4ZqRQZ32GhtraUh1UCMJNIQQQnQJhUJBuLcj4d6O3DaxL5UaLVuPFDaURy8gq7SGTcmFbEou5MU/DuHnbMvEcA+iA11YcyiPv/Ybd7j08bDnrTmRDA10MZ17RXwWGw4XYKVS8ursIZ3av+XEWhpCAg0hhBDdhIO1BecP9Ob8gd4YDAaOFlSZZjt2pBaTVVrD9zvS+X5HepPHvT03ikh/tel2YaWGF347CMC900Lp5+nQqa9DZjSakkBDCCFEt6NQKOjn6UA/TwdmR/uzZHsab/93uMVjL/toC15O1g1LLJ78sS+Hkup6+vs4ceuEPp08crBqqBkiMxpGEmgIIYTodgwGA3HpJXy3PZ3fE3JMF217KxVXjQxkVrQ/O1OLWZ+Uz7aUIvLKNfwUm8lPsZkAKBXw2uzBXVIw63hjNQk0QAINIYQQ3UhFbT0r9mTx3Y50EnMrTPcP8HHimlFBXBrli4O18dLV38eJ68YEU1uvY2dqcUNuRz5HC6q4e0ooQ/ydu+Q1WEur+CbOKtB49dVXefzxx7n33nt59913zTQkIYQQ55r9WWV8tyONlfHZVNcZt4VaWyi5NNKXq0cFEemvPmUNDBtLFRPCPJgQ5sHTlwygSqPF3rrrPkc3BhqyvdWo3T+JXbt2sWjRIoYMGWLO8QghhDhH1NTp+G1fNt9tT2NvZpnp/n6eDlw9MpBZQ/1R21m2+bxdGWTACa3iZUYDaGegUVlZydVXX81nn33Giy++aO4xCSGEaAODwcA/B3IJcLVjoK/6zA/oYsl5FXy3I51f4zKpqNUCYKlScOEgH64eGcjIENce115drzeQUljF3oxSUouqAAk0GrUr0Fi4cCHTp09n2rRpZww0NBoNGo3GdLu8vLw9TymEEOIUPt+Uykt/HsLN3oqtj0/p9E6praHR6vh7fy7f7UhnZ2qx6f4AV1uuGhHEnBh/3Duw2Zm55VfUEp9eyt7MUvZmlLE3s9QUNDVysm37bExv1OZA44cffiAuLo5du3a16vhXXnmF559/vs0DE0IIcWbrEvN5+a9DABRV1fHPgTwujezYxmFtkVZUxfc70/k5NpPiqjrAuCNkWn8vrh4VxPh+7p1aTKs9qjRaErLK2JthDCzi00vJLqttdpyNpZLBfmqiApwZHuzKtP5eXTDa7qdNgUZGRgb33nsv//33HzY2Nq16zOOPP84DDzxgul1eXk5AQEDbRimEEKKZ5LwK7l66B4MBvJ1syC2vZemO9C4PNLQ6PasP5fPdjjQ2JRea7vd2suHKEQHMGx6Aj7pz+o60lVanJzm/kviMUvZmlBKfUcrhvAr0hqbHKRQQ5ulIVEPX2qgAZ8K8HLDogu203V2bAo3du3eTn59PdHS06T6dTsfGjRv58MMP0Wg0qFRNp+ysra2xtu4502FCCNETFFfVcdPXsVRqtIwMceWNKyKZ9OY6tqUUkVJQSR+Pzq2GCZBdWsMPuzL4cVc6eeXGJXOFAiaEenD1yECmRHh2qwuxwWAgu+z4Ekh8eikJWWXU1DffLeKjtmkSVAzyU5u22YrTa9N3aerUqSQkJDS574YbbiAiIoJHH320WZAhhBDC/Oq0eu74djfpxdUEutrx6TXDcLG3YnK4J2sS8/lhVwZPXNy/U8ai0xvYmFzAd9vTWZuYZ/rk72ZvxdzhAcwfHkigm12njOVMymrq2Zd5fKYiPqOMwkpNs+McrS0YEqAm0t/ZFFx4ObVuFl8016ZAw9HRkUGDBjW5z97eHjc3t2b3CyGEMD+DwcCzqw6wI7UYB2sLPr8uBhd7KwDmjwhkTWI+v+zO5MHzwzo0KbSgQsNPsRks3ZlOZkmN6f6RIa5cPSqICwZ6dWlSap1Wz6GcctNMRXxmKSkFVc2Os1Aq6O/jRGRDYDE00Jk+7g7dPm+kJ5F5HyGE6EG+3nqMpTvTUSjg/flRhHk5mr42KdwDH7UNOWW1HZYUejC7nI/WH+HfA7nU64zTF042Fswe5s/VIwPp5+l4hjOYn8Fg4FhR9QkzFaUczC6nTtd8e2mQmx2R/seXQAb6OmFjKbPxHemsA43169ebYRhCCCHOZOPhAl743diV9ImL+jMloumuBguVkrkxAby3JrnDkkJv+SaWrFLjDEZUgDNXjwzkkiG+2Fp13sW6qFJzwkyFcTdIWU19s+Nc7CyJDHA2LoEEGv/r2jD7IzqPzGgIIUQPcLSgkoXfx6E3wJxh/tw8PqTF4+YND+CDtckdkhRaqdGagozld45haKCL2c59KjV1Og5kl5lmKvZmlpJRXNPsOCsLJYN8nUwzFVEBzgS62vW4wl+9kQQaQgjRzZVV13Pz17FU1GqJCXLhxcsHnfIC6uts22FJoccKjTkOrvZWHRJk6PQGjhZUHg8qMkpJzK1Ad/LeUoxlyhtnKqL8nQn3djR1TRXdiwQaQgjRjdXr9Cz8Po7Uwir8nG359NphZ0yy7Kik0GMNpbWDzbSLJLestklQkZBVRqVG2+w4D0dr0yxFVIAzg/3VONlI1c2eQgINIYToxl78/SCbjxRiZ6Xi8+tiWlWme1K4h6mA178H8phhplyNtKJqAILd7M/qPIs2HOXLLammWhsnsrNSGatrNsxURAY446O2kSWQHkwCDSGE6Ka+3Z7G19vSUCjg3XlR9PdxatXjLFRK5g03JoV+vyPdbIFGasPSSbD72QUay/dkmYIMbycbJkd4mOpVhHo6opKtpb2KLGgJIUQ3tPVIIc+uOgDAQ+eHc/5A7zY9fu7wAJQKTEmh5pDWsHQSdJZLJ+/PH2o6R1lNPeP6eTBveCAR3k4SZPRCEmgIIUQ3c6ywiju+i0OnN3BZlC93Turb5nP4OdsyKdwTgB93ZZhlXKmFxqWTkLOc0QjzcmTlwrGMD3Wnpl7Hwu/jeOOfxBaTPkXPJ4GGEEJ0I+W19dz8TSxlNfVEBTjz6uwh7c5PuGpEIAA/785Eo23ev6MtKjVaU7nuoLPM0QBwtrPiq+uHc+uEPgB8tO4ot3wTS3lt83oYomeTQEMIIboJnd7A3d/v4Uh+JT5qGxYvGHZWVSsbk0KLq+r490DeWY3txK2talvz7PiwUCl54uL+vDsvCmsLJWsT87nsoy0cNdNSj+geJNAQQohu4uU/D7HhcAE2lko+WxCDp+PZNfKyUCmZOzwAgO93pJ/VuRq3tvq7mL+9+2VD/fjl9jH4qm1IKajisg+3sObQ2QVGovuQQEMIIbqBH3el88XmVADenhvFID+1Wc47z0xJoZW1xvoW+zLLuP6rnRzOqzDL+BoN9lez6u5xjAh2pUKj5eZvYvlwbTIGg+Rt9HQSaAghRBfbmVrMUyv2A3D/tDAuHuxjtnObKyn0sqF+3DA2GAulgvVJBVz47kYeX5ZAQUXzWhjt5e5gzbc3j+SaUYEYDPDmv4dZ+H0cVS0U8RI9hwQaQgjRhTKKq7n9293U6wxMH+LDPVP7mf055pshKdTGUsWzMwby3wMTuXCgN3oDLN2ZzqQ31vHBmmRq6s4u2bSRlYWSFy8bzCuzBmOpUvBnQi6zP9lKRnG1Wc4vOp8EGkII0UUqNVpu/jqW4qo6BvupefOKyA6pgDnZjEmhIe72fHrtMH66bTSR/mqq6nS89d9hpry1nl93Z6I30xbV+SMCWXrLKNwdrEnMrWDGh5vZcqTQLOcWnUsCDSGE6AI6vYH7fthDUl4Fno7WfLYgpsNarZ+YFLp059klhTYaEeLK8jvH8t6VUfg525JTVsuDP+9lxoeb2XrUPAFBTLArv989jkh/NaXV9Sz4cidfbE6VvI0eRgINIXox+YPcfb3xTxKrD+VjbaFk8YIYvNVnt8PkTBqTQrceLTKVEj9bSqWCmVF+rHlwIo9dFIGjtQUHssu56rMd3PS/XRzJP/ttqt5qG368bTSzo/3R6Q383+8HefDnvdTWm2epRnQ8CTSE6KW2Hikk/Om/uXLxNrYdLerq4YgT/Lo7k083HAXg9SuGEBXg3OHPeWJS6A9mmtVoZGOp4vaJfdnwyGSuGx2ESqlgTWI+F7y7kadX7DcV+jqb8785ZwjPXDIAlVLBsrgs5i3aRk5ZjZlegehIEmgI0Ut9suEodVo921OKmf/ZduYtkoCjO9idVsLjyxIAuGtyP2ZG+XXac5sjKfR0XO2teH7mIP69fwLnDfBCpzewZHsak95Yz8frj5zVLIRCoeDGcSF8c+MInO0s2ZtZxowPthB7rNiMr0B0BAk0hOiFsktr2NyQODc72h8rlZIdqRJwdLWs0hpuWxJLnU7PBQO9eOC8sE59fnMmhZ5OXw8HPlsQw9JbRjHYT02lRsvrfycx9a0NrNiTdVYJo2P7ufPbXeOI8HaksFLD/M+2n3UxMtGxJNAQohdaFpeJwQAjQ1x5a24k6x+exLWjgpoEHHMXbWPr0ULJ4+gk1XVabvk6lsLKOvr7OPH23CiUndyptCOSQk9ndF83Vi4cyzvzIvFV25BVWsN9P8Zz2cdb2JHS/mA3wNWOZXeOYfpgH+p1Bp5YnsCTyxOo0+rNOHphLgpDJ/+VKS8vR61WU1ZWhpOTU2c+tRDnBIPBwOQ313OsqJo350RyxTB/09dyymr4ZP1RftiZQZ3O+Ed5RIgr900LZXQftw7ZWilArzdw53dx/H0gF3cHK1beNQ4/Z/OX8m6NrNIaxr22FoMB1j006aw7sbZWbb2OLzan8sn6o1Q2FOA6f4AXj10UQR8Ph3ad02Aw8PH6o7z5bxIGA4wIduWjq6PxcLQ259BFg/Zev2VGQ4heJjathGNF1dhbqbh4sHeTr/mobXlh5iA2PDKJBaONMxw7U4u56rMdzFu0na1HZIajI7yz+jB/H8jFSqVk0bXDuizIgIak0DAPwPxJoadjY6li4eR+rH94EteMCkSlVPDvwTzOf2cjz67cT3FVXZvPqVAoWDi5H19cF4OjtQU7jxVz6YebScgs64BXINpLAg0hepmfY41lpi8e7IOdlUWLx5wYcFzXGHAcK+aqzyXgMLeV8Vl8sPYIAK/MGsywINcuHhFcNTII6Lik0NNxd7DmxcsG889945ka4YlWb+DrbWlMfH0dn29Kadf7bkqEFyvuGksfD3tyymq54tOtrNiT1QGjF+0hgYYQvUh1nZY/9uUAMCcm4IzH+6htef7EgMPieMAxd9E2tkjAcVb2ZpTyyC/7ALhtYh9mn7CM1ZUmh3vg5WTd4Umhp9PP05Evrh/O9zePZKCvExUaLS/+cYjdaSXtOl9fDwdWLBzLlAhPNFo99/0Yz0t/HESrk7yNriaBhhC9yF8JuVTV6Qhys2N4sEurH9cYcGx8eDLXjwnGykLJrmMlXC0BR7vlltVyyzexaLR6pkZ48sgFEV09JBMLlZJ5MZ2XFHo6Yxp2kQzwMa75F7VjCaWRk40lny2I4a7Jxn4xn21K5Yb/7aK0uv3nFGdPAg0hepGfdxuXTa6I9m9XYqe32obnLh3IpkeaBxxzPt3G5mQJOFqjpk7HrUtiya/QEO7lyHvzh6Lq5B0mZzJvRCAKM1cKbS+lUoGrvRXAKZuzGQwGEjLLeHf1YV7589Apm6yplAoeuiCcj6+OxtZSxabkQi79cAtJueZtay9aTwINIXqJjOJqtqcUo1Bw1lP0Xk7NA47YtBKu+UICjjMxGAw8/Mte9mWW4WpvxefXxeBg3XKuTFfqqqTQU2ns81J9QqBRW69jzaE8Hl+WwKhX1jDjw828uzqZRRtTmPrWBl747eApk0gvHuzDsjvH4O9iS3pxNZd/vIW/9+d0ymsRTUmgIUQv8cvuTADG9XPH10y7Gk4MOG4Y2zTguOLTbWxKLpCA4yQfrD3C7/tysFQp+OTqaAJc7bp6SKfUlUmhJ7NrCDTSiqr4YWc6N38dS9QL/3LT17Es3ZlOXrkGOysVFwz0Ylw/d+p0er7cksqE19fx4dpkquu0zc7Z38eJ3+4ax5i+blTX6bj92zje/jfJbB1mRetIHQ0hegG93sD419eRVVrDe1dGdVhZ67zyWj7dcJTvd6SjaSiONCzIhXunhjI+1P2cr8PxV0IOd3wXB8Brswczb3hgF4/o9LQ6PWNfW0teuYYPrxrKJUN8O30MBoOBQzkVXPz+pha/7qO2YVp/L6b292RUHzdsLI0ByabkAl79K5ED2eUAeDhac9+0UObGBGCpavoZWqvT8/KfiXy5JRWAaf29eGdeJI42lh34ynqf9l6/JdAQohfYeqSQqz7fgaONBbuenGb6Y9xR8str+XRDCt/tSDMFHNGBztw3LeycDTj2Z5Ux59Nt1NTruHFsCM/MGNDVQ2qVt/9N4v21RxjT143vbxnVKc+p0erYdrSINYfyWXMoj+yy2iZfj/RXM7UhuBjg42R6P9Vp9VhZHA8i9HoDvyfk8OY/SaQ35Gz0cbfn4QvCuXCQd7P34a+7M3m8oYJoP08HFl87rN3Fws5FEmgIcQ574Md4lu3J4qqRgbx8+eBOe96WAo6hDQHHhHMo4MivqGXmh1vIKatlYpgHX1wXg4WqZ6xMd1al0KJKDWsT81lzKJ+NyQVNcjFsLJXU1hvfPxcN8uaTa4Y1eaxOb+DNf5P4fFMKz186iKtGNp0pqtPq+X5HGu+vPWLK2YgKcOaxiyIY1cetybF7M0q5bclucstrcbSx4P35Q5nc0NVWnJ4EGkKcoypq6xn+0mpq6/Usu3MM0YGt39ZqLvnltSzamMK328+9gKO2XseVi7cTn1FKXw97li8ci1MPm5K/4audrEsq4LaJfXj8ov5mOafBYOBwXiWrD+Wx5lAeezJKOfFq4+VkzZQIL6b192RsP3e+2nKM1/5O5Iph/rw5J9J0XGl1Hff8EM/GwwUAPHlxf26Z0KfF56yoreezTal8vinFFMhMifDkkQvDifA+fr3Jr6jljm/j2J1WgkIBj1wQwe0T+/Tq96k5SKAhxDnqh53pPLYsgb4e9qx+YGKX/rHMr6hl0YamAUdUgDP3TQtlYphHr/tDbjAYeOCnvSzfk4Xa1pKVC8cS3Em9Q8zp3wO53LpkN272Vmx7fGqT5Ym2Sswt54edGaxJzCOjuKbJ1wb5OTE1wotp/b0Y5OfU5P3w9dZjPLvqANMH+/DR1dGmc936zW7TsoijtQWbH5uC2vb0gVx+RS0frDnC0p3paPUGFAqYNdSfB84PM5V/12h1PLfqAEt3GreEz4j05fXZQ0y7X0Rz7b1+d789V0KINmncbTInJqDLL+SejjY8fckAbpvYh8UbUvh2RxrxGaVc/9WuXhlwfLohheV7slApjTtMemKQAcZP/V5O1uSVa/j3YO5ZJYVeuXg7pdX1ACgUMCnMw5Rv4aM+9W6o49tbjbtH/tiXw8O/7G2yxHLdmOAzBhlgfB/+32WDuHFcCG/+m8Qf+3L4NS6T3/Zlc93oIO6c1A8XeytemTWEgb5qnlt1gN/2ZnM0v5JF1w7r1juFeqKesYgohGhRSkElsWklKBUwa2jH7DRpD09HG566ZAAbH5nMzeNCsLFUmgKOyz7eyrqk/B6/Lfa/g3m8/k8iAM9dOpAx/dy7eETtd2Kl0O93nF1NjRvGhGDVkJ9iMEB5rZYAVzu8nWxO+7jG7a2VGi2v/Z3Iwu/jqK7TmWqQ2FqquHFcSJvGEuJuz0dXRbNy4VhG93GjTqvns02pTHhjHR+vP0JNnY5rRgXx3c0jcbO34mBOOTM/2sK2o+1vYS+ak6UTIXqw1/9O5OP1R5kc7sFXN4zo6uGcUkGFhsUbj7Jke5op6S+yYYZjUg+c4TiUU87sT7ZSXadjweggXpg5qKuHdNYyS6oZ//o6sySF5pTVsGhDCt/vTKdOe/znfe/UfkwO92zx570uMZ8b/reryX23jA9hd1oJceml3DwuhKcuaf9OHoPBwIbDxi2xiQ1VQr2dbLj/vFBmR/uTX6Hh1iWx7M8qR6VU8PT0/lw3JrjHvTc7krSJF+Ico9MbWBZn7FDZmgZqXcnD0Zonpw9g0yNTuHVCH2wslezNKOWGr3Yxb9H2U5ad7o5Kq+u4+etYqut0jO3nxtNncfHrTvxd7I5XCt11drMaPmpbnrt0IJsfmcxNDTNaezNKufF/scz4cDP/HshtNqOVUXK8pLiNpZL3roxiWn8v4tJLsVIpT5kA2loKhYJJ4Z78ec943pkXiZ+zLbnltTz6awIXvreJ/Vll/HzbGC6L8kWnN/Dcbwd59Nd9XV7IrDeQQEOIHmrzkUJyy2txtrNkav+esT3Pw9GaJy7ubwo4AHYeKzYl+/UEL/x2kKzSGoLd7Pj4qmHNikP1ZPNHGLeN/hKbaZqJOBueTsacnU2PTOG2CX2ws1KxP6ucW5fs5uL3N/NXQg56vYE/9uXwzMoDpsf9escYZkb58eG6IwDMifHH6wxLL62lVCq4fKg/ax+ayFPT++NsZ8mR/EpuXbKba77YwdWjgnjy4v4oFfBTbCbzFm0nr7z2zCcWp9R7fkOEOMf8HGvMlp8Z6Yu1Rc/KlPdwtOaeqaGm277O5rmIdLS1iXks25OFUgFvz4tCbdeztrGeSWNSaFFVHf8ezDXbeT0crXn84v5sfnQKCyf3xcHagkM55dzxXRx9nviThd/HNTl+oK+a+IxSNiUXolIquH1iX7ONpZG1hYqbx/dh4yOTWTi5LzaWSnanlTDn023sSC3myekDUNtaEp9RyowPNhOX3r729UICDSF6pLLqev49mAd0/2WTU0krMnYMdbW36hGloMtq6nl8WQIAN40L6ZJ6JR2to9vHu9pb8fAFEWx+1NisryWNTW4/XGuczbgsyq9Dd4E42Vjy8AURbHh4MvNHBKJSKlh9KI+X/jhIhLcjTjYW5FdouHLRdn7aldFh4+jNJNAQogdatS+bOq2eCG9HBvr2zKTqxjbfgT1kK+GLvx8kr1xDiLs9D54f3tXD6TBzhwegUMCWI0Uc66D28XnlGtYl5bf4Nb0Bnlt1gNWH8lAo4M7J5p/NaImXkw2vzBrMP/dN4MKB3ugNsCO1mPJa43bbOp2eR37dx7Mr91OvO/tlpXOJBBpC9EC/NCybXDHMv8dmxacV9ZxAY31SPj/vzkShgNevGNLhvWS6kr+LHRMbkkKXnmVSaEv+TMjh8o+3kFZUjZ+zLX/cM46E587nvmnHl9L+t/UYYNweG+DSue+Pfp4OfHrtMJbdOYYRwa7Nvv71tjSu+XwHRZWaTh1XTyaBhhA9zOG8CvZmlmGhVHB5N6qd0VZpDTMaQW7dO9CoqD2+ZHL9mGCGt3Dx6W2uMnNSKBh3Sb3+dyJ3fhdn2rHz293jGOirxtHGkvumhbX4uMlvrm/opdO5uz+iA1348bZRfHFdDOFejk2+tiO1mEs/3ML+rLJOHVNPJYGGED1MYyXQKRGeuDlYd/Fo2i+9h8xovPxnIjlltQS62vHwBb13yeREUyI88XQ0X1JoWXU9N/5vFx+vPwoY62N8fcMIXO2tmhznaNO0WLWHozVZpTU8uXw/k95YzzfbjlFb33kBh0KhYGp/L/68dzxvXDEEH/XxpOWs0hqu+HQrq/Zmd9p4eioJNIToQep1elPtjCuG+XfxaM5OWrFx/T/IrfuW7f5tb7YpKfK12UOwszo3ujZYqJTMG26epNCk3Aou/WgzGw4XmOpjPDl9QIvdbSsa8iEAlt85hk2PTOa5GQPwcrImp6yWZ1YeYMLr6/hyc2qn1l5RKRXMiQlg3UOTeOLiCFMZ9Np6Pfcs3cMrfx1Cp+/ZlW47kgQaQvQgG5IKKKzU4O5gxeSInlE7oyX1Oj3ZpcbaBN116eSPfTnc92M8ADeMDWZ0X7fTP6CXmWeGpNCT8zEa62OcibWFkqGBLthYqrh+bAgbHp7M/102CF+1DfkVGl74/SAXvLux05dTbCxV3DqhLxsfnsztE/ti3dB8btGGFG7/dnePL6vfUSTQEKIHaVw2uSzKr0cXisourUGnN2BtocSjGy7//JWQwz0/7EGnNzAr2o+npveO6p9tcTZJoafLxziV/BOKYp3c08TGUsW1o4JY//BkXpk1GKUC0ouryS/vmoRMtZ0lj10UwbqHJjE3xh+lAtYm5lOp0Z75weegnvuXSohzTHFVHWsSjbUzrojp4csmJ+RnKJXda9fM3/tzuHtpQ5Ax1I83rohE1c3G2FnaUym0tfkYJ/tsU4rp/wf7tRyQWFkomT8i8Kza2JuTr7Mtr18RybqHJvHXveN7RD2YrnBuLDgK0Qus2JNFvc7AYD81Ed49s3ZGo+664+SfA7nc9f0etHoDl0X58sacczfIAJjakBSaX9G69vFJuRXcuiSWtKJqbCyVvDZ7SKuWSoqr6vh2+/FZk+oz5F8oMP5MustKRXfOM+oOukdYKIQ4o58blk3m9PDZDID0hqqgga7d5w/0vwdyWfhdHFq9gZlRvrw1N+qcDjKgbUmh7c3HAPhqSyo1J+wmqak7/RJEY+kYA90k0hCnJYGGED3AgewyDuWUY6VScmnk6T9V9gSNSycdMaOxJ72E2GPFbXrMfwfzWPi9MciYEenLW+f4TMaJzpQU2p58jBOV19abCnQ5WBsn2c80o6FUdK8ZDXF6EmgI0QP8HGuczThvgBfOdqdf6+4JGru1Bpo50Ciq1HDl4u1c9dkOCltZuXHNoTzu/G439ToDlwzx4Z25kS1uvTxXnS4ptL35GCdasi2NilotYV4OzIwyBtFVZ1w6MZI4o2eQ3yYhurk6rZ6V8Q21M3rBsonBYDgeaJi5WNfv+3LQaPXU6fRsOVJ4xuPXJuZxx7dx1OsMTB/sw7vzoiTIaEFLSaFtqY9xKtV1Wj5vSAK9c1I/04zGmZZOGiMN2U7aM0gyqBDd3NrEPEqq6/FysmZCqEdXD+esFVbWUV2nQ6EAfxdbs5572Z4s0/9vPFx42hyBdYn53L4kjjqdnosHe/PulRJknMqUE5JC/ztobHb20M97qa7T4edsy6JrhzHoFDtFTmfj4QJKquvxVdtwyRAfjjXk7pw5GdRIwoyeQQINIbq5xmWTy4f694q8gfSGiqC+alusLczXnCyloJK9GaWm25uSCzAYDC02nVuflM9tS3ZTp9Nz0SBv3rtyaI+uS9LRLBuSQj9Ye4RnV+2nsLIOgDF93fjwqug2LZWcyEdtDDRLquup0+mxt2pdjobClKMhoUZPIL9ZQnRj+RW1rD9cAPSO3SbQcV1bVzTMZozp64aNpZL8Cg1JeRXNjttwuIBbG4KMCwZ68f58CTJaY26MMSm0Mci4eVwI39zYtnyMkw3xVxPoakdNvY61ifnYWhkDz+rW7jqROKNHkN8uIbqxFXuy0OkNRAc609fDoauHYxbpHVBDw2AwsLwhj2Xe8ABGhhjLhW863DRPY+PhAm75JpY6rZ7zB3jxwfxoCTJaKcDVjvkjAnGxs+S9K6N46pK25WO0RKFQMH2IDwC/783BzhRotHLXyVk9u+gs8hsmRDdlMBhMyyZXDAvo4tGYT2PX1gAzzmjsTisho7gGB2sLzh/gzfhQdwA2JheYjtmcXGgKMs4b4MWHV0V3mwqTPcVLlw0i7unzWl0fozWmDzYGGuuS8mnsS9bqHA2JNHoE+S0Topvam1lGcn4lNpZKLon06erhmE1HVAVtTAK9cJA3tlYqJjRsx9yZWkxtvY7NyYVc88UONFo90/p78pEEGe2iUChazHk5GwN9nQhxt0ej1bP1qHEG6sw5Gsb/SsGunkF+04ToJIWVGrYdLaKqlY2Xfo7NAODCgd449aIeCqZiXWaqCqrR6vhjXw4Alw81ftIO9XTA28kGjVbPq38lcs0XO0zHf3S1BBndiUKh4JKG5ZMNScYZqDNub+1mJcjF6cmuEyE6yW1LdrM7rQRLlYJhQS6MD/VgQqgHA32dmjUWq63XsWpvNtC7lk2qNFpTIS1zFetal1hAWU093k42jOpjzM1QKBSMD3Xn592ZpqqTAOP6uZt1p4swj0uG+PLB2iMUVRkTTVs9oyGBRo8ggYYQnaC8tp649BIA6nUGtqcUsz2lmDf+ScLV3opx/dwZH+rO+FAPvNU2/Hswj4paLX7Otozp69bFozefxkRQZztL1LbmmaVZvseYxzIzyrfJ9t/E3KY7TmZG+fLelUPN8pzCvMK9HQn1dCA5vxJofY6GXiKNHkECDSE6QXx6KQaDcUvnNzeOYFNyARuTC9l2tIjiqjpW7c02zWCEeTmgaai+ODvar9u1UT8bph0nZkoELa2uY21iPgCXRx9PUHx6xX4SsspMt+ePCOCVWUPM8pzngruX7iGrpJqnLxnA0ECXTnnO6UN8eHd1MmDc3nqqGihwfNeJ6BnatFD5ySefMGTIEJycnHBycmL06NH89ddfHTU2IXqNxtmM6EBngt3tuXZ0MJ8tiGHPM+fx022juXtKPyIDnFEo4HBepSmPYfaw3lE7o5G5d5z8kZBDvc5Afx8nIrydMBgMzF+8nSXb05ocNzzY1SzPd644kF1GXHqpKeDtDCe2oNcbOO1zy9JJz9KmGQ1/f39effVVQkNDMRgMfP3118ycOZM9e/YwcODAjhqjED3envRSgGafDi1VSkaEuDIixJUHzw+npKqOrUeL2Hq0kAhvR4Lcuk8bdXNIa6gKaq4dJ8vjjLtNLh/qS229jnGvrWvSTC3YzY5jRdVsSi5kVnTvCto6UrXGuHTR2HukM/TzdCDC29G05FVdp8PGsuV8muMlyCXS6Ana9C6aMWNGk9svvfQSn3zyCdu3b5dAQ4hT0OsN7DHNaJx+GtrF3orpQ3xMRYx6G3PuOEkvqiY2rQSFAsb0dSfi6b+bfP3L62OwtbRg/mfb2ZRciF5v6FXLUB2pqmHXR2MBrc4yI9KXxNwkwLh8cqqqowppE9+jtHuPl06n44cffqCqqorRo0ef8jiNRkN5eXmTf0KcS1IKKymv1WJjqSTCx7Grh9OlzNkefkVDJVBvJxsu+WBzk68tuWkEUyK8iA5yxs5KRWGlhkO58renNQwGg2kLtn0nzmjA8eJdcOaEUJDKoD1FmwONhIQEHBwcsLa25vbbb2f58uUMGDDglMe/8sorqNVq07+AgN6zVU+I1ohLKwVgiL/zOV3uWqvTk1VSA5z90onBYGB5Q5GunLLaJl/74dZRjG/ocmttoTJted2UfOa28cKYG9FYobOzZzSC3e2Z1t8TdwdrfNQ2pzzueI6GhBo9QZv/6oWHhxMfH8+OHTu44447uO666zh48OApj3/88ccpKysz/cvIyDirAQvR08S1ctmkt8spq0WrN2BlocTL8dQXkdaIzygltbCq2f2/3jHaFFg0aixHvumEcuTi1E4sKGdn1fkbEz+/bjjbH5+C42mK1DXuOtHpJdDoCdr8LrKysqJfv34ADBs2jF27dvHee++xaNGiFo+3trbG2tr67EYpRA92PBHUuUvH0RoZxdV8vP4IbvbWhHk70tfDHrWtJY42ljhYW5xVm/rG/IwAF9uzzpVorAR6opULxxIZ4Nzs/sbZjV2pJdTU6UwdQkXLGpcsbC1VZ/XzPhtnatbm52xLenE1ibkVxMiOom7vrMNVvV6PRqM584FCnIPKa+s5nG/Mou8JMxq3fBPbrNBVS3zVNixeEIOP2gZXe6tW9b84vuPk7BNB92aWNrn9xz3jGOirbvHYvh72+KptyC6rZUdqEZPCPc/6+XuzxkRQe+vuG5CN6uPGtpQitqUUcc2ooK4ejjiDNgUajz/+OBdddBGBgYFUVFTw/fffs379ev7555+OGp8QPdreDGOhrgBXWzwcu//M3o3jQnjkl31nPC67rNaUgGltocTX2RYftQ0+alv8nG3wabjdeL+jjaWphkbgWdbQ+G1vNruOlZhu/3PfBMK9T51kq1AomBDmwQ+7MtiUXCiBxhk0Lp10xbJJa43u68Y7q2FHStFpC3uJ7qFN76T8/HwWLFhATk4OarWaIUOG8M8//3Deeed11PiE6NEaE0F7wmwGwNyYAObGGBO2dXoDBRUaskprSCuq4nBeJf8eyCWlITfC3cGawkoNGq2e1MKqFnMmGjnaWJi2Ip5NIuiKPVnc92O86faaByfS18PhjI8bH9oYaEiexplUNdTQ6OxE0LaIDFBjbaGksLKOowWV9PM8t3dzdXdtCjS++OKLjhqHEL1ST04EVSkVeKtt8FbbMCzIOP5J4R5cuXg7fdztWfvQJDRaHblltWSX1pJTVkNOWS1ZpTXklBr/P7u0hvJaLRW1xxMMB/u1vMRxJr/szuShn/eabq9/aBLB7qdfhqnT6rFUKRjbz81UdTW3rBbv0+xoONdVNyyddGaxrraytlARE+zCliNFbDtaJIFGN9d930lC9HB6vYH4jFKgZySCtkZxQ3dNl4ZCStYWKoLc7E+bd1Gp0ZJTWkN2WS02Fsp2Je/V1uuaBBmbHpl8xjLmH607whv/JDFnmD9vzIlkiL8zezNK2ZRcwJwY2WZ/KqYZjW4caACMCnFjy5EitqcUc+3o4K4ejjiNc3dTvxAdLKWwirKaemwslfT3cerq4ZhFY6BxqoqNLXGwtiDUy5GJYR6M7NO+TrQKBYR7GT+1bnlsyhmDjGVxmbzxj7HC5PbUIgAmmLa5tlxPw2AwUHnC1s5zlSkZtBsvnQCMauhqvL0hT0N0X907ZBWiB2tcNhni13sKdTUGGm5tCDTMwdpCxd/3jW9V0t/6pHwe+On47MeqheMAY57GB2uPsPlI83Lkm5ILePH3QyTlVeDvYsuwIBdiglyIDnIhwtupy7Z5doXjORrd+/IQ6e+MjaWSoqo6kvMrCfOS5ZPuqnu/k4TowRr7mwwNcu7agZhRe2Y0zKU1QcbutBKu/2qX6faGhyeZlnmGBjpjb6WiuKqOgznlDPJTk5xXwct/HmJd0vEk0cySGjJLalgZnw0YP9kPDTQGHcOCXBga6IzTaYpJ9XTVPWB7K4CVhZKYIFc2Hylke0qRBBrdmAQaQnSQnrbjpDWKujDQOJP9WWXM/mSr6fYvt49ukjtiqVIyuq87qw/lsWJPFj/uyuD7neno9AYslAquGxPMjeNCSC2oIjatmN1pJexJL6VSo2XzkUI2HzEuuTQu40Q3zHoMC3Ih0NWu12yxbJzR6Ow+J+0xqo8x0Nh2tIgFkqfRbXX/d5IQPVDFCYW6eksiKEBxlbE4X3cLNA7llDdprPbelVEtJp2O6uPK6kN5fL451XTf+QO8ePzi/oQ07GDxc7ZlXEM+h05v4HBeBbvTSkz/GitSJuZW8P2OdMC41XdYkDPDGgKPQX5qrC2694zAqZgaqnXzHA0w1tMA2JFaLN15uzEJNIToAHszyjAYwN/FFs+z7OvRnRRX1QPdK9BIzqvgovc2mW7fNy2UmVF+TY4xGAz8tT+XF/84ZLovxN2ely8fbLpYtUSlVNDfx4n+Pk6mCpT5FbXEnRB47M8qp7BSwz8H8vjnQB4AViolg/3VpsAjOtClRxRsgxNbxHf/y8NgP2dsLY3LYYfzK4jw7h1J171N938nCdED9eT6GafTOKPhZt89LppHCyo5752NptuXRvpy79TQJsfszSjlxT8ONqkmCvDExf1PG2SciqejDRcO8uHCQcaW5rX1OvZnlbE7rYTYtBLi0kooqqozBSKNgtzsTIHHsCAXwjwdu+Un8MZeJ909RwMa8jSCXdiUXMj2o0USaHRTEmgI0QGOBxrOXTsQMzIYDMeTQR26fkbjWGEVU9/aYLod6a/m7bmRplyJnLIaXv87ydRO3sZSya0T+pJeVMWK+Gy2HCnkvAFeZz0OG0sVMcGuxAS7chvG71NaUTWxDYFGXFoJh/MrSCuqJq2ommVxxvE42lgwNNCFYYEuxAS7EBng3C2KZJmWTrrBWFpjVB83Y6CRUsz1Y0O6ejiiBT3jnSRED6LXG0wdW6ODes+MRoVGS73OWK+gs7e3niyjuJqZH20x3XZ3sGbJzSOxUCmp0mhZtOEoizelUFuvB2DWUD8evjAcH7Utf+/PYUV8doeVI1coFAS72xPsbs8Vw/wBKKupZ0+6MeiITSshPqOUilotGw8XsPGwcRxKBUR4OxETfHy5xd/FttOTTE0zGj1g6QSMgQYY66VInkb31DPeSUL0II2FuqwtlL1qKre40jibYWelwsay66bVs0prmLdoG2U19ab7lt85BnsrC36KzeDNf5LIrzAu8YwIduWpS/ozxN/ZdOzovu4oFXC0oIqs0hr8nG0B40xEWU09znbmD6LUtpZMCvc0NXTT6vQk5jZNMs0qreFgTjkHc8r5ZlsaAF5O1qagIybYlQE+TlhZdFxNlqJKDQlZZUD37nVyoiH+auysVJRW15OUV9FriuP1JhJoCGFmjfUzhvirO/SiYE7ltfV8tPYILvZWRAe6MMRf3SyYKK5uKD/eARfi1sotq+Wqz7aTXVZrum/5nWPIKKnmtiW7OZhTDhg7xD5+UQQXDvJuNiPgZGNBXw8HkvMr2ZxcwKxof/5MyOHzTakkZJVx/7Qw7p3WNM/D3CxUSgb5qRnkp+a6McGAcaknLq20IfAo5kB2OXnlGv5MyOXPhFzA2Ck30t+ZYcHGJZfoIBezJeamFVU12R781/5cIgOcuzSobA1LlbGs/cbDBWxPKZJAoxuSQEMIM4trXDbpQYmg65MKWLQxxXTbQqlgoK+TMYegoUJm44yGWxflZ+RXGIOMtIZ28wAPXxDOx+uP8t9B424PRxsL7pkSyoIxQS1uL62oreeRX/aRnF8JwNdb03hvdXKTwOWd1YcJ83LgosE+HfyKmvJR2zJ9iC3Thxift6ZOx77MUlOC6e70Ekqr69l5rJidx4pNj+vjYc+whp9TTLALfdwd2rx8UFChYcGXOyls+BkD/G/rMZbvyeKKYf5cPTKQPq3okttVRvdxY+PhArYdLeIGydPodhSGTi4SX15ejlqtpqysDCcniTxF73PhuxtJzK3g02uGceEg764eTqusS8rnhq92YWWhxNnW0rT0cCoDfJzwdbalSqOlpLqOIDc7PrwqusNKrRdWapi/eLspQGhkoVSg1RtQKRVcPTKQe6eG4ubQ8o6YxNxy7vg2rsV29u4OVlw7KpjCSg1LtqdhZ6Vi2Z1jutXSl8Fg4GhBlWlrbWxaMUcLmr8Wta0lw4JcuGFsMONDPc543kqNlvmLt5OQVYa/iy2ZJTWAcUdHnVZvOm5cP3euGRXItP5eWHSzkvp70ku4/OOtqG0t2fP0eZKn0UHae/2WGQ0hzKii1rhODD1rx4m3k7HWR51Wj74Vnz0acwkaJeZW8M+BXC4Z4mv2sZVU1XHN5zuaBRkAWr2ByeEePDm9/2lbhf+6O5MHT+j+2qifpwM3jwvhsqF+2Fiq0Or0pBZWsflIIbd+s5tVd43tkJyN9lAoFPTzdKCfpwNzhxu7z5ZU1bEno4TYY8bgY29mKWU19axNzGdtYj7XjQ7isYv6Y3uKfIs6rZ47vt1NQlYZrvZWLL42hovfN9Yk2fXkNOLSSliyPY11Sfmm6qheTtbMHxHIlcMD8VZ3jxoxg/zU2FupKKup51BuOQN91V09JHECmdEQwow2JxdyzRc78HO2ZctjU7p6OK1WXFVH9P/91+x+G0slbvbWWFsqSWnh0/PJ/JxtG5IXnRkW5EqEj2OrZzkMBgPpxdVNyoaXVddz1efbOZBd3uz4cC9Hnpzenwlhp/7UXluvY9Ib68ktr21y/5i+btwyvg8Twzyaffotqarj0o82k1Fcw/hQd766fni3+wR/KvU6PQezy/l5dwbfbjdWLe3rYc+784Yy2L/pxVevN/DAT/GsiM/G1lLF0ltH4e9iS8yLqwE4+vLFpmZyGcXVLN2Zzo+7Mkxl6FVKBef19+KaUUGM6evW5bMI13+1k/VJBTx9yQBuGifLJx1BZjSE6AYaE0F72rZWF7uWm4S5O1hz56R+XDHMn8eXJfBrXCaPXhjB7RP7kFZUze60kiYzBVmlNWSV1rBqr7EhmY2lMXkxumHnRHSgc4tLGyVVdcz4cDN55bXsfvo8nGwsKa+tZ8GXO5oFGRZKBS/MHMTcGP9TBgC19TreW5PMJ+uPNrn/0khfbp3Qh0F+p/7E69LwyX7Wx1vZlFzIa38n8uT0Aac8vjuxVCmJDHAmMsCZ8wZ48/DPezlaUMXlH2/hvmmh3D6xr+l79urfiayIz8ZCqeCTa6KJCnAmvSH/xdZS1aRjbYCrHY9cGMG900L5e38u321PZ+exYv4+kMvfB3IJcbfn6pGBXDHMv8tmgEb1cWN9kjEhVAKN7kUCDSHMqKcW6lIoFAS42pJRXMOSm0aQmFPBoo0pZJbU8MTyBD5cezxh0tXeskmtCGc7S276OhZftQ1vzIk0FqlqqBlRXqtlR2oxO1KPJy8Gu9mdEHi4EO7tiIu9FdYWSup1BtYeymfaAC8ufm+TKV+g0fTBPrw6ezCOp+ieWtSQY/Hu6uQm90d4O/Ll9cPxbdjKeib9fZx4a24kd34Xx2ebUhnoq+ayoX5nfmA3MjHMg3/um8CTKxL4MyGXN/89zLqkAt6eG8l/B/NY3JD8+9rsIaZtt1V1py/WZW2hYmaUHzOj/EjKreC7HWksi8sitbCKF/84xBv/JDEj0pdrRgUR6a/u1BogoxvqaexIKULXkLcjugcJNIQwE4PBwJ6MUqBn7Thp5OVoQ0ZxDeU1Wm6Z0IdrRgWxdGc6izYebbIrY2V8NpdG+pnW/Qc3zA7kltcyNNCZsf2MDcn0egMphZUN1TFLiUsvITm/kmNF1Rw7oUKmg7UFkQFqU2LjpxuOct+P8c3G9/bcSGZF+7c49qMFlXy+KZVfdmeYioo1+u/+CYS2o4X4xYN9WDi5Lx+tO8qjv+6jr4dDs+WH7s7F3oqPropmWVwWz646wO60Eia+sd709UcvjGD2sOPf07a0iA/3duSFmYN49MIIVsRn8e32dA7llPPL7kx+2Z3JID8nrhkZxKVRvp3SN2WgrxMO1haU12o5lFN+2lkr0bkk0BDCTFIKqyitNhbq6ol7+b0aEvsa8xlsrVTcOC6Eq0YG8nNsBk+vPADA1qNFjH99HbdOCOGaUUF4Otng4WhNQYWGQzkVDGtYNlIqFfTzdKSfpyPzhgcCxpyLPRnG2Y649FL2pJdQqdGy5UiRaRyJuRXNxtZSkGEwGNiRWsznm1JYfSi/2WOuGRXIM5cMPKtaJg+cF86hnArWJuZz25JYVt09DvdT7GrprhQKBbOH+TMixJXxr69r8rU5MU2/p5UNLeLbEhjYW1tw9cggrhoRSFx6Kd9uT+OPfTnszyrnsWUJvPTnIWZH+3PNqMDTJuyeLQuVkuHBLqxrWD6RQKP76BkZTkL0AHENDbQG+/WcQl0n8mroMpt/UuKkjaWKa0cHY6k6PhVdWKnh5T8TGffaOj5ef4SQhgTOA9llp30OtZ2xQuYD54fz7c0j2ffcBfx173guP82yxD1T+jUJMup1elbGZ3Hph1u4cvH2ZkGGnZWK9+cP5cXLBp/1z0GlVPDulVH0cbcnu6yWO7+No16nP/MDu6GymnpsTyq+deG7G1mbmGe6XX0WLeIVCgXDglx4Z14U25+YyuMXRRDoakdFrZb/bT3GtLc3cuXibfy+L7vJtllzamyStz2l6AxHis7U8/4aCtFNmZZNelgiaCNvtfGT+sk7NMCYXNm4JBH39Hm8fsUQgtzsKK6q4/W/k0wFpLYeadsf+KySGj5ce8TU+Oxkl0b6cv95YYBx6/Dnm1KY9MZ67v0hnoSssmaBRD9PB1bdNZZLI823zdbJxpLFC2JwtLZg57FiXvjtoNnO3VnSiqq4/qud1NTrGN3HjRULxxLm5UBhZR03/i+WJ5YnUF2nRas3/ozTi6vJKq05w1lPzdXeitsm9mX9Q5P4+sYRTOvvhVIB21OKuev7PYx9bS1v/ZtE9lk8R0sa+57sSC1Gp+/UDZXiNCTQEMJMGmc0eloiaCOvhloaeS0EGo1dWy1VClzsLJkbE8CaBybyzrxI+ngc347694Fc3v7vMKXVdc3OcaLy2npe+fMQ097ewB8JOSgVMH9EAK/MGmw6ZrCfmtevGEJOWS0v/XGQMa+s5cU/DpFVWoObvRW3jA9haICz6fhLI31ZuXBsh0zP9/N04N0ro1AoYMn2NH7YmW725+gohZUarmuo+tnfx4lFC4YRFeDMqrvGcXPD7ozvd6Rz8XubcLK1JNDVjvwKDVcu3nZWwQYYl88mhnnw+XUxbHp0CndP6Ye7g3GZ7YO1Rxj32lpu+SaWDYcL0JshMBjoq8bR2oKKWi0HW9gSLbqGBBpCmEGlRsthU6GunjmjcTzQaF4VtDHQcLGzMu0ksFApuXyoP//dP5HHL4owHfv+mmTGvbaO1/9OND2ukVanZ8m2Y0x6Yz2LNqZQp9Mzrp87f9wznucuHcgvuzNNxw4LcuHRX/cx4fV1fLYplQqNln6eDrw6azBfXj+c1Yfy2ZFajKVKwQszB/LelVEd2tp8an8vHphmnF15euV+djcElt1ZlUbLjf/bxbGiavycbfn6huE4NezYsbFU8dQlA/j+5pH4qG04VlTNjf/bxag+rvg5G3cgXbl4G5kl1Wd4ltbxc7blwfPD2frYFD68aiij+riiN8B/B/O47sudTH5rPYs2HG32nmkLlVLBiBBXQJZPuhMJNIQwg70ZpegNxj+mnk7do1piWzVWB80tq+XkOn6NRZpaauClUiq4dUIfnE+oxVGp0fLx+qOMe20tL/95iIIKDeuS8rnwvU08vfIAxVV19PWw58vrY1hy0wgivB159Jd9TS7e/9t6jJXx2Wj1Bkb3cePL62P4974JWKiUzFu8jdTCKnzVNvx022gWjA7ulK2Ud03px0WDvKnXGbj9290tzv50F/U6PXd8F8e+zDJc7Cz55qYRLb43x/Rz5+97JzAzyhed3sBPsZnU6/QoFDQEG9vNFmyAsbT5JUN8+eHW0ax+YALXjwnG0dqCtKJqXvkrkVGvrOGBH+PZnVbS7H3YGqa28RJodBuy60QIM2hcNhnaQ5dN4PiMRk29jgqN1vTJF6C4yjjLcaqGagqFgsF+ajYlF/J/lw3Cy9GaD9YeISGrjMUbU0w1G8BYHOz+88KYPyLQVDX09YbiUSe7ZIgPt0/syyA/NbX1Op5ckcDSnRmAsU7Eu/OicDFT99LWUCgUvDknkpSCKpLyKrhtyW5+uHVUt+twqtcbePSXfWw8XICtpYovrx9O39M0RVPbWfLelUOZ2t+Lp5YnNOl1k1liDDaW3jKKAFc7s46zn6cjz106kEcuDGdVfDbf7khjf1Y5y/ZksWxPFv19nLhmVCCXRfm1eraqMSF0Z2oxWp2+x1R17c3kJyCEGfTk+hmNbK1UONkY/5jnlTX9pF5cVQ+Aq/2pt3Y2bic8mF3O+QO9jQWyWuiFMTHMg2n9vbBUKSmq1DDlzfV8fEIFzxN3Rlw1MpBBfmoyiqu54tOtLN2ZgUIB908L46vrh3dqkNHI3tqCxQuGoba1JD6jlGdW7m/XJ++O9No/iSzbk4VKqeDjq6MZ2sr35aWRvvxz/wTG9nNrcn9jsJFRbL6ZjRPZWVlw5YhAfrtrHCsWjuWKYf5YWyg5lFPOk8v3M/LlNTyzcr9pefJ0+vs44WRjQYVG26Qfj+g6EmgIcZYMBkOPLT1+ssYmWSfnaZhmNE5zYW8s3LU7rZhP1h9l8pvrTYW+HKwt8HA0Bikr4rMZ8+pagh/7g2EvriblhG6qT03vz84npzK3ob7D3/tzWX0wj+nvb2J/VjkudpZ8fcMI7p0W2qW9NYLc7PnwqqEoFfBTbCbfbEvrsrGc7IvNqSzaYJxBenXWYCZHeLbp8T5qW5bcOJJnLhnQZFdPVmnHBhtgnDGKCnDmzTmR7HhiKk9N70+Iuz2VGi3fbEvj/Hc2MvfTbayMz0Kj1bV4DmOehjFQ2nZUlk+6Awk0xDkrtbCKYy20DG/PeUoaCnUN6IGFuk7UuHxy8hbXE5NBTyXU0zg1fzivktf+TqSyoSaDn7MtAa52WCgVp22AdvjFi7h5fB8cbSy5cJA3AN9sS+Pmb2Ipr9UyNNCZP+4Zf9pzdKbxoR48flF/AF74/WC3uKit2pvN//1u3H778AXhzIkJaNd5lEoFN44L4fe7xzV5TzcGG409UTqSs50VN4/vw5oHJrLkphFcMNALlVLBzmPF3PtDPGNeWcvrfye2GPiM6iMJod2JBBrinFOn1fPGP4lMfWs9F7638ayDjbj0UqDnFuo60am2uBZVNiSDnpSjUVpdx9/7c4h5cTXnvbOxxXNmldZwKKecnLJaNh4uOOVzP/brPo4WGFvBh3s3DdiuHxPMj7eObnWvks5y8/gQLmtIolz4fZxZkybbauuRQh78KR6A60YHceekvmd9zjAvR1YsHMvtE/vSmGtrDDa2dUqwAcagZ3yoB4uujWHLo1O4d2ooXk7WFFXV8fH6o0x4Yx03/m8X6xLzTbUzGhNCdx0rQdtDC6z1JpIMKs4ph/MquP/HeFNH0Np6PS/8fpAvrx/e7nM2NlLryYmgjbycjMsbJwca2WXGegobkvJJL6oiKa/ytEEDGGcyTq7DoFDAnGH+bDxcaJo1GejrxIFsYwLg8vgsfJxsmvRW8VXb8NylA8/6tXUEhULBq7OHcKSgkv1Z5dy2ZDe/3D7G1Aems+zPKuPWJbup1xmYPtiHZ2YMNNsuHCsLJY9dFMGUCE/u/zGerNIasstquXLxNpbeOoogN/szn8RMvNU23H9eGHdN6ceaQ3ks2Z7GliNFrE3MZ21iPv4utlzV0EVWbWtJWU09+7PLiTqh3orofD3745cQraTXG/hicyqXfLCZA9nlONtZ8tT0/liqFKxNzGfNobwzn+QU9jTMaPTkRNBGHg19PL7ZlsY7/x3mjm93M+XN9ezPMgZmqw/l89mm1BaDjABXW9xPmPEor6lv8nV7KxWxT05DgYLc8lrsrVT8ec94/rhnPKvuGsu0/l4YDDQJMsBYr6O7JVueyMZSxaJrY3Czt+JAdjmP/rqvU8ebUVzN9V/tolKjZVQfV96aG9khnUtHhLjy933jmd1QDt4YbGwnp8y81T1bw1Kl5MJBPnx38yjWPjiRm8aF4GRjQWZJDa//ncTYV9eacjhk+aTryYyG6PWySmt4+Oe9bG1YQ58U7sHrs4fg6WRDQaWGRRtSeP63g4zt597mbYqVGi1JucaLcIhH532yO1sGg4G8cg1JeRUk5ZaTmFvB4bwKU0AB8N6a5NOcwWhEiCsPnBfGyBBXDmSXM+PDzaavVTTkaIDxU/H2J6by3Y50fozNQKmAD64aygBf4xJJsLs9Fqe4OKYXV/NzbCZzh7cv36Az+Dnb8vHV0Vz9+Q5W7c1moK8Tt008+6WLMymq1LDgy50UVmqI8HZk8YKYDt1q62hjyVtzI5nW35MnlieQU1bLmkP5XDMqqMOe80z6eDjw9CUDeOj8cH7bl81329PYm1lmKpm/M7WY2zvhZyFOTWHo5I8K5eXlqNVqysrKcHLq2YlzonszGAysiM/imZUHqKjVYmup4snp/bl6ZKBpWrlSo2XqW+vJK9fwwHlh3DM1tE3PkVJQyZS3NgCYkh1nRvly3gCvVnfALKmqo6hKQ4i7Q4d8Ei2rqSc5r4LE3AqScisagosKyk6acTjZnGH+hHs70s/Tgeu/2mW630qlZFa0HzePD6GPuwPrD+fz2cZUtp30yfGzBTF8uDaZvZllLJzcl8F+am7/Ng6A52YM4PqxxvLXh3LKuePb3RwrqsZSpeCZSwYwIsSND9cd4be9x2trTInw5O4p/Vq9VbMrLNl2jKdXHkCpgK9uGMHEDkxcrdJoueqz7ezNLMPP2ZZld44x5dh0hvyKWjYdLuSiwd6d0ga+LRIyy4xdZBNymDc8gKcvGdDVQ+oV2nv9lkBD9EolVXU8uSKBPxNyAYgKcOadeVGEuDefdVi1N5t7lu7B2kLJ6gcmtqkokcFgYOnODL7bkWbK+wBjLYjzB3oxM8qX8aEepsJUJ9NodYx4aQ1lNfXYWCqJ8HZioK8TA3ydGOirJsLbsdWfUDVaHUfyKzncEFQcbggsTl6KaKRUQIi7PRHeToR7OxLm5ciS7cfYcqSImVG+vHflUNNrvODdjeRXaLh2VBDXjg7CycaSFXuy+GxTCkcLjMm0KqWCiwf7mIKDF2YO5JmVB7C2UPLJNdHc+V0ctfV6rh8TbMq5+GV3Jk+tSKC2Xo+fsy0fXR3dZD39zX+S+HDdkSbjfuTCcO6c1K9V35POZjAYeOzXBH6MzcDJxoJVd40juIX33Nmq1+m55ZtY1icV4GJnyS93jDltQS4hzEECDSEarE/K55Ff9pFfocFCqeCeqaHcOanvKSsEGgwGrly8nR2pxVw40JtPrx3Wruc9kl/BqvhsVu7NJu2EjHwXO0suHuzDzCg/YoJcmtR/MBgM3LZkN/8ebDlHRKmAvh4ODGwIPAb4OtHfx4nymnrTzETjLEVqYdUpO1b6qG0I93Y0/vMy/revh0OTIKZKo2XES6upqtOx9JZRpgqLYLywqRQK9AYDH68/yjfbjlHYsBPF0dqC+SMDuX5MML7Otsz9dJupmyvA1AhP9mWVUVChYXK4B58tiEGrN/DcqgP8sOv0VT7LauqJefE/6nUGrFRK6nR6rhjmz5tzIlv7Y+l0Gq2O+Yu3E5deSpiXA8vuHIuDGXuwGAwGHvp5H7/GZWJjqeT7W0b1ivwg0f1JoCHOedV1Wl7+8xDfbjd21uzrYc8786IY4u98xscm5VZw8fub0OkNfHPjiLOq1WAwGIjPKGVlfDa/78uhsPJ48Ss/Z1tmRPoyM8qXCG9HFAoFBoOBn3dn8vKfhyitPr6cYW2hRKNt29Y8JxuL4zMU3o5ENMxUqG0tz/jYn3Zl8Miv+wh2s2PdQ5Na3LXQeEzja7lhbDDzhgfgeEK58ud/O8BXW46ZbttZqaiu0xHh7cgvd4yhuLKOO77bzYHsclOVz7sm9ztlAa7rvtzJhhOST7+6fnibi1B1tvzyWi75YDP5FRouGOjFJ1cPM1uBsdf+TuST9UdRKRUsvnYYU/t7meW8QpxJe6/f3WthTYh22pNewgM/7SW1oSbG9WOCeeyiiFYvO4R7O3Ld6GC+3JLKc6sO8Pd9E9pdE0OhUDA00IWhgS48Nb0/21KKWBmfzd/7c8kqreHTDUf5dMNRwrwcmBnlx6WRvsyNCWBqhCcv/5nIr3HGDqZOtpbcPrEvIe52HMgq52BOOQeyy0kvrsbKQkmop0OTGYoIbye8nKzbva3xh13GAG3e8MBTniMm2AVbSxU19TouG+rLzeP7NDumsUJoo+o6HR6O1nxx/XC2Hy3igZ/iKa/V4mJnyfvzhzI+9PRB3UWDvE2BhruDFeND3dvz8jqVp5MNi64dxrxF2/nnQB4frjvS5vyflny1JZVPGsq1v3L5YAkyRI8gMxqiR6vX6flg7RE+WncEnd6At5MNb8wZcsaLV0vKa+uZ8uYGCis1PHZRhNkz1WvrdaxLzGdlfDZrE/OpO6GQUHSgMzOj/Jg+xIfDeRU8tXy/qTT3pHAP/m/mIFPuSHWdFiuV0qzNog7nVXD+OxuxUCrY+vgUPB1PnVS4Mj6Le3+IB+DzBTFMG9D0YvffwTxu+SbWdNvGUsnSW0bx78E800VyaKAzH10V3aoCXEWVGoa9uBqA8wd4sXhBTFtfXpf5KTaDR34xzgB9tiCG8wa0PzD4fV82dy/dg8EAD50fxl1Tzj5wEaIt2nv9ljoaosc6kl/J7E+28v6aZHR6g7Eh1H0T2hVkADjZWPL4RREAvL8m2ez1AWwsVVw02IdPrx3Grqem8foVQxjbzw2Fwlhd9NlVBxj58hoWbUjhlgl9uHlcCFYqJeuTCjjvnQ18sv4o9To9dlYWZu9I+UNDR9Sp/T1PG2QAzIzy47rRxu2M9/8UT1pR08qqJ9ckeWr6AF7/O8kUZLS1yqflCTNLre3gCRCfUcraxLxT9sToDHNjAo5/r36M50j+mZuCtWTr0UIe+HEvBgMsGB3EwsndMxlWiJbIjIbocfR6A0u2p/Hyn4fQaPU42Vjw4uWDuTTS1yznnrNoG7vTSpgR6csH84eaYcSnl19ey2/7clgVn8XezDLT/dYWSvp4OJCUW05jjme4lyMvzxrMsBOatxkMBtYcykephFBPR/ycbduUD1Bbr2PUK2sora7nqxuGMzn8zPkPdVo9Vy7eRlx6Kf19nFh2h7EaZn5FLSNeWtPkWE9Ha/IrNNhbqXh19hBmtPHn9OOudB79NQGAmCAXfrljzBkfU1SpYfSra6nT6nG2s2TGEF9mRfsRFeBstoqZrVWv03PN5zvYkVpMiLs9KxaObVXOTKMD2WXMW7SdSo2WiwZ58+FV0R2yDVqIM5FkUHFOyC2r5eFf9rIpuRCA8aHuvHFFpKnrqDnszyrj0g83ozfQbPdFR0strDLuXInPatLV9GRXjQzk0QsiUNtZsj4pv0mdC3srFaFejoR5ORDWkL8R5uWIp2PL+RuN23t91TZsenRKqy9iOWU1XPL+Zoqq6pgd7c+bc4YYe04kNa8aGurpwCfXDKOfZ9u3YM5btI0dqcZdLAoF7Hh8Kp5nqBexLC6TB37a2+z+Ph72zI7257Khfvh1Yt+UokoNl364hazSGiaFe/DFdcNb9X3OKK5m1idbKajQMCLElW9uHNGhBbmEOB0JNESv99vebJ5asZ+yGmOn1Ccu7s+1o4I6pF340yv2s2R7GmFeDvxxz/hT1sHoKAaDgQPZ5ayMz2LV3uxmbdsB3B2seWbGAA5klbFoYwpONhbU1OtMFRFPpra1JNzLkVAvB1PwEeblyF3fx7H1aBH3Tg3l/vPC2jTOrUcKueaLHegNcOuEPizemNLsmJlRvrx8+eA2LXs0yiiuZvzr61AojDMjeeUa/u+yQVx7hkqUdy/dw297s7ljUl9G93FjWVwmfx/Ipbb+eF7M6D5uzIr246LBPmbdfnoq+7PKuOLTrdTW67lzUl8euTDitMcXV9VxxSdbSSmsIsLbkR9vG92mmRAhzE0CDdFrlVXX8/TK/axqKAQ1xF/N23Oj2vXpuLVKq+uY/OZ6SqrrefqSAdw0LqTDnutMdHoDO1KLWBWfzZ8JOZTXals87vUrhnD5UD/SiqpIyjUW7jqcZ6yxcaywilOU2DA5b4AXUyI8CfNyINTLESeb1l3UPll/lNf+Tjzl11NevrjdweCHa5N589/DjOnrxsQwD175K5Fx/dz59uaRp3yMVqdn2IurKaup55fbRxMTbGwZXqnR8ldCDsvisppUMbWxVHLhQG9mD/NnTF93sy9L1Ov05JXXklNWyzfb0kwFzT6+OpqLB/u0+JjqOi1XfbaD+IxS/Jxt+fWOMWadtROiPSTQEJ3iUE45Gw8XcPlQvzNOX5vD5uRCHvp5L7nltaiUChZO7sfdU/p1ygzD0p3pPL4sAUdrC9Y8NPGMSZKdQaPVsSGpgJV7s1l9MK9JnY3VD0ygn6dji4+rrdeRUlBlCj6M/ypJLz51q29ftQ2hJyy9hHk50M/ToVm5aYPBwA3/28X6E5ZMGvMyADY8PKldHT4NBgNT395ASkEVb1wxhBEhrkx8Yz0qpYLYJ6c1K+7VaHdaMbM/2Yba1pLdT01rMXE2s6SaFXuyWBbXdInKy8may4b6MTvanzCvlr+XJ9Lq9ORVaMgprSGnrJacsob/ltaSU15LTmkNBZUaWvorOzHMg69vHNHs/nqdnlu/iWVdUgHOdpb8cvvoU/5chehMUkdDdIr31yTz1/5c3ll9mAWjg7ltQh/cGjp+mlNNnY7X/k7kf1uPAcZS2W/PjezUPhfzYgL4YWc6ezPLePWvRN6eG9Vpz30q1hYqzh/ozfkDvamoree91cl8vjkVgD7up57hsbFUMaChtHkjrU5P1Av/Gfu9RHjSx8OepLxKkvMqyCmrJbvh34nFshQKCHCxa8j9cDAtv5w/wNsUaEwK9+CduVFc99VO9mWWsT+rvF2Bxr7MMlIKqrCxVJqWN/r7OHEop5zVh/KYE9Nyk7V1icZxTAjzOOXuHH8XO+6aEsrCyf2IzyhlWdzxJapFG1JYtCGFCG9HJoR5EBPkQp1OT25ZLdmlJwQTZTUUVGjOOFMEYKlS4K22wcfJFh9nG7zVNlzR0AX1RAaDgceXJbAuqQAbSyVfXDdcggzR40mgIdrk9ol92XKkkPJaLYs3pvDd9jRuGBvCLeP7oLYzz/rxvsxS7v8x3tRD45pRgTxxcf9Ob9ykVCp4fuYgLvtoC8visrhqRKBpGr47cLSxNPXRGB/q3ublibWJ+VRqtLg7WPHJNcOaFChrbMR2OM+4BJOUW0FyfgWFlXWkF1eTXlzN6kMtl00f4u/MtpQibBuSFvdnlzF9SMtLBKezfE8WAOcP8DblUFw40JtDOeX8vT/31IFGUj4Ak8NPvc1ZpzdQUKEhu6yGnNJagtzsmBnly/c70tE2RA6JucaeMYvPME5LlQIvJxt81Db4qG0b/muDt9oWX2fjfW72Vq36+bz5bxK/7M5EqYAP50c32V0kRE8lgYZok8gAZ36+fQwLvtxBXrmGqjodH647wtfbjnHL+D7cMDa4STnqttDq9Hy8/ijvr0lGqzfg4WjN61cMadV2y44SFeDMvJgAfozN4JmVB/jt7nHdamvhnvRSAIae0IistX5s6DMyO9q/WRVUta0lMcGuzQKrwkoNh/MqSM6rJCnP2LjtcF5Fk7yR909qL//J+qNkl9aYZj/CvRzxdzn9Ftx6nd6UkzMr2s90/0WDvXln9WE2JRdSqdE2S+LMK681NbdT21ryV0IO2WW15JbVkF1mXMrILaslr0Jzyr4wrXHrhD5cPNgHX7UN7g7WZklI/nrrMT5aZ6w18vLlg5sVQhOip5IcDdEuGcXVLPhyp6nkdyMXO2PZ7AWjg7G1av02vNTCKu7/MZ74jFIALh7szUuXDT7lOnxnKqrUMPnN9ZTXavm/mQO5dnRwVw/JZMpb60kpqOLL62OYEtH6C1NOWQ1jX12L3gBrH5xIn7Po/GkwGMgr15CUV0Fyw+zH4byKJjVBTmZrqSLUy8GU+9G4DdfbyQaFQsHqg3nc/E0s7g7WbH98imkJRK83EPn8v1RotEwf4sOwQBdyy2vJbgggYtNKWj1ulVKBl6M1Ps62eKtt8G2chVDb4ONsnJlwd7AmtbCSZXFZLN+TRc4JnXCD3eyYFe3P5UP92tTxtyV/JuSw8Ps4DAZ48Lww7jZDuXIhzE2SQUWnK6zUcP1XO9mfVd7sa+4O1iyc3Jf5IwJPu+/fYDDw3Y50XvrjEDX1OhxtLHhh5kAui/Lr9MJKp/PNtmM8s/IATjYWrHtoUofkpbRVaXUdUS/8B0Dc0+fh2oag7IM1ybz132FGhLjy022jO2R8tfU6Ip7+GzAuf1XWaknKq+RoQSV1p2gW52hjQZiXI7tPCBjG9nOjTqsnu7SWvPJa09LGmTQuYTQuZ3irbfA1BRW2eDhat2l2Sqc3sD2liF/jMvl7fy7Vdccrjo4IcWV2w1bZ1u7WabTtaBHXfbmTOp2ea0YF8n8zB3Wr974QjSTQEF2ioraeW7/ZzbaUIlRKBZPDPUnKKyej2Fi+20dtw11T+jFnWECz6fn88loe+XWfKYlwTF833pwT2erS1J1Jq9Mz48MtHMopZ/6IAF6ZNaRLx1NYqWHES6tNiYjHXp3e6sfq9QYmvLGOzJIa3pkXyeVDmyclmsvF723iYE45n14zjAsHeQPG72VacXXDskulaQvu6drcn8qUCE9C3O3xUdvg4Wht6sHy6x2jGRbUcfk0VRot/xzIZVlcFluOFpp2lVhbKLlgoDezov0Y18/9jKXiD+WUM/fTbVRotFw40JuPrpaqn6L7kkBDdJnaeh33/RDP3wdyUSrg+UsHolIq+WBtsmmqOcDVlnumhHL5UD8sVEr+SsjhieUJlFTXY2Wh5NELI7hhTHCHFN8yl9hjxVzx6TYUClhx51gi25EXYQ6bkgu4/8e9TdrPtyXQ2JRcwLVf7MTJxoKdT07r0EqTj/yyl59iM7l7Sj8ePD/8tMdqtDpSC6tIyq3goZ/3nrLw2IlObBm/PaWIKxdvx83eil1PTuu091JOWQ0r9mTza1wmR/IrTfd7OFpzWZQvs6L96e/T/G9dZkk1sz7eSn6FhhHBrnxzk1T9FN2bbG8VXcbGUsVHV0fz1IoElu7M4OmVB3j4gnDWPTSJpTvT+WjdUTKKa3j4l318sv4o4d6O/LU/F4CBvk68My+qVTULulpMsCuzhvqxbE8Wz6zcz/I7x3ZqYFSn1fPWv0ksOqn65v3T2lbNs7GB2uVD/Tr8wjbYT81PsZnszzp1vkYjawsVEd5ORHg7MTPqeAJoTZ2OI/lNC5Al51VSUVuPp9PxJazG3SYTwjw69efio7bljkl9uX1iHxKyylgWl8XK+CwKKjR8timVzzal0t/HidnRflwa5Yunow0lVXUs+HIn+RUawr0c+ey6GAkyRK8lgYYwC5VSwcuXD8bV3oqP1h3ljX+SKKqs46np/blyeCDfbDvGpxuOklJYRUphFUoF3DGpL/dODWu2pNKdPXZRBP8ezGNvZhk/785g3vDATnneY4VV3PPDHva1kGA5OaL13WqLKjX8e9AY5HXG2Af6qQFIyCrHYDC0K/fA1krFYH81g/3Vpz1ufeLxOh5dQaFQMMTfmSH+zjxxcX82HC5gWVwmaw7lcyinnBf/KOeVvxKZEOpOUVUdKQVV+Kpt+N+Nw6W0uOjVJNAQZqNQKHj4gghc7a35v98P8uWWVEqq63j9iiHcNrEvV40M5Kstx4hLL+HuKf06dA29o3g62XDftFBe/OMQr/2dxAUDvXG269idMcv3ZPLU8v1U1elQ21pibaE0Vd20VCmI8G79FOayuCzqdQYi/dVNind1lP7eTigVxpyS/AoNXh1UTTa7tIakvAqUCpgQ2jWBxomsLJScN8CL8wZ4UVpdx2/7clgWl8me9FJT0zm1rSVf3zgCH3X3y0kSwpwk0BBmd9O4EFzsLHn4l30s35NFaXUdH189DEcbS+7pBdv2rhsTzI+7MkjOr+Tt/w7zwsxBHfI8lRotz6zYz7KGwlUAvs62HMo5vstniL9zq2eEDAYDP+xKBzpnNgOMsxH9PB04nFfJ/qyyDgs0GhOKhwa6dIst0SdytrPi2lFBXDsqiJSCSpbvySI+o5QHzgsjtAcsGQpxtnrOnLXoUWZF+/PZgmHYWCpZl1TANV/soLS6rquHZRaWKiXPzxwIwLfb0ziQfeb8g9bQ6Q2kFlbx74FcblsSy6Bn/2kSZABNggwwVspsrdi0Eo4WVGFnpeLSKF+zjLk1BpmWT8zzfWpJY37GpLCun804nT4eDjx4fjhLbhrZqeX0hehKMqMhOsyUCC++vWkkN/5vF7vTSpi3aDtf3ziiV3ShHNPXnUuG+PD7vhyeXXmAn28f3er8A53eQFpRFcn5xr4iyfmVHD5DfQlrC2WTBmqvzR7M6D7uBLq1vlDU0p3G2YxLhnROW/RGg3zVLIvLarHeijnkl9ey5UghgGkHihCi+5BAQ3SomGBXfrp9NAu+2ElSXgWzP9nKtzePJMS97U22upsnp/dnbWI+sWklLN+TxayTmmQ11otIbtglkdywcyKlsOqUAcXJ3poTSUywC7ZWKqa9tcFYnfSyQW1e+iirqefPhByg85ZNGh2f0ShFpzeYpU5EvU7P+qQCftyVwbqkfHR6A15O1gxoYRupEKJrSaAhOlyEtxM/3jaayW+uJ6u0hslvru/wgkqdwUdty91TQnnt70Re/jMRawsVRwuMwcSR/EpSCqqo07UcUNhYKgn1dCTU04FQL0eyS2tYsj3N9LXnZgxk3vAA0yzJI7/spbxWy0BfJ64a0fZAYVV8FrX1esK8HIgOdG73a26PAb5OWKmU5JVrmPXxFl66fLAp+GirI/mV/Bybwa9xWU3qiAwNdOap6f27dR0WIc5VEmiITuHl1LRk9+xPthEV4MxHV0fj1w0rgbbWjeOC+Tk2g5TCKhZ+H9fs67aWxmTIUC8HQj2P9/XwczY2FdNodbz+d5IpyIjwduTDq4Y2aQ0el17CT7GZALwwc1C7ZgR+aGigNm94YKeXt3awtuCNOUN4avl+9maWcemHm7luTDAPnh/eqiWcSo2WP/fl8GNsRpPS5G72VsyK9mNuTIAkVQrRjUllUNFp4jNKueyjLc3uv2CgF9eNCWZ0H7ce2eNhZ2oxD/wUj6u9lXGWwsuBsIbAojGgaElKQSV3L91j6jZ6/ZhgHrsooknhJp3ewMyPNrM/q5wrhvnz5pzINo8vIbOMGR9uxkqlZMcTU7tsV0Z+eS3/98chfmvoyurtZMOzMwZw4SDvZj93g8HA7rQSforN4Pd9Oaa+IkoFTA73ZO7wAKZEeGJ5hhLfQgjzkRLkokeo1+l56Y9D/G/rsWZfC/NyYMHoYC4f6od9JyYrdjaDwcAvuzN5dtUBqut0uNhZ8sYVkS22Bf9uRxpPLt+Po40Fax+chIdj25u5Pbk8ge92pDMj0pcP5g81x0s4KxsOF/DMyv2kFVUDxn4lz186kABXO/IralkWl8VPsRmkFBzvDBzibs+cGH9mR/t32BZZIcTpdUqg8corr7Bs2TISExOxtbVlzJgxvPbaa4SHn76HgTkGKnqXjYcLWPDlzha/5mhjwZxhASwYHURwD00ara3XsSo+mwG+Tgz0dTJ9Yi+vreep5ftZ1fCpfnQfN969MqrFi2dJVR2T31pPaXU9z84YwA1jQ9o8juo6LSNeWkOlRsv3N49kTD/3s3thZlJbr+OjdUf4dMNR6nUGbCyVxAS5si2lyNRYzdZSxfQhPsyNCWB4sEuPnO0SojfplEDjwgsv5Morr2T48OFotVqeeOIJ9u/fz8GDB7G3b90FQQIN0aioUsOwF1ebbj9yYTg/7crgWMMnXYXCWBdhwZhgJoZ2bv+Ks7VkexpPr9gPQLiXI5dH+xHsZsdLfx4io7gGlVLBA+eFcfvEvqfMuXh8WQJLd6YT4e3I73ePO2Mn0JMZDAa+2nKMF34/SKCrHesfmtTtvodH8it5cnkCO1KLTfdFBzozNyaA6UN8cGxjy3UhRMfpkqWTgoICPD092bBhAxMmTGjxGI1Gg0ZzPDu8vLycgIAACTQEYLwYfrYpBScbS64cEYheb2BDcgHfbD1mKtUMEOxmx7Wjg5kT449TD7j4/BSbwSO/7Dvl17+7eSRjTzO7sC+zlJkfbcFggJ9uG82IkNbv0KmorWfFniy+25FOYm4FAA9fEM7Cyf1a/wI6kcFg4M+EXI4VVXH+AC9J7BSim+qSQOPIkSOEhoaSkJDAoEEtl2F+7rnneP7555vdL4GGOJNjhVUs2Z7GT7EZVNRqAbCzUjEr2o8Fo4O7dcfXLUcKufrzHViplC1ucbWzUnHhQG9mRfszuq9bk1kNvd7A5Z9sZW9GKZcP9eOdeVGtft4Ve7J4YnmCKXnSxlLJrGh/nrlkgHQHFUKclU4PNPR6PZdeeimlpaVs3rz5lMfJjIY4W1UaLcv3ZPHNtmMczqs03T+mrxsLRgczrb9nm5cVOlpqYRWT31xvum1npeLmcSEolQqW78kyJUKCcevvZUP9mDXUn3BvR37clc6jvybgYG3B2gcn4tmG5MfblsTyz4E8AlxtuXFsCLOG+qO26/4zQEKI7q+9gUa7U/sXLlzI/v37TxtkAFhbW2Nt3fZMeSEa2VtbcM2oIK4eGci2lCK+2ZrGvwdz2Xq0iK1Hi/BztuXqUYFcOTwQ127QUKu2XsfijUdNt/1dbPnmxhH08XAA4N6pocSll7IsLpPf9+WQV65h0YYUFm1Iwc/ZlqzSGgDumxbapiADIMTdAchjUphnu5JHhRDC3No1o3HXXXexcuVKNm7cSEhI2/6YSTKoMIes0hq+257G0p3plFTXA8bW3DMjfbluTHC7K0+erSP5Fdz1/R5TbgTAyoVjiQxwbvF4jVbHusR8lsVlsS4pn3rd8V/H8aHuzIkJ4PwBXq1e9li+J5P7f9zLiBBXfrpt9Fm9FiGEOFGnLJ0YDAbuvvtuli9fzvr16wkNbXvLbwk0hDnV1uv4bW82X2871qRp17AgFxaMDuKiQT6tbqN+NgwGAz/uyuC53w5QW6/Hzd6Koipjt9ovrothav/mNTJOtjm5kGu+2NHsfgdrCy4e7M3lQ/0ZGeJ62p0jB7LLmP7+ZtS2lsQ/c55sCRVCmE2nLJ0sXLiQ77//npUrV+Lo6Ehubi4AarUaW9ueW0Za9Fw2lirmxARwxTB/4tJL+WbbMf5MyGF3Wgm700p40fEQV48M5KoRgW1ehmitspp6nliWwB8NTcvGh7rz1txInl6xn38O5JHdsBRyOnq9gXdWHwaM3VXvPy+MFXuyWBaXRVZpDT/FZvJTbCZ+zrZcNtSXy4f608/Todl5+no4oFQYx5RfoZHiVkKILtemGY1TfTr66quvuP7661t1DpnREB0tv6KWpTsy+G5HGvkVxkRkC6WCiwf7cN2YIKIDzVf8KfZYMff+EE9WaQ0WSgUPXxDOLeP7oFQqeG7VAf639Ri3T+zLYxdFnPY8v+zO5KGf92JnpWLNgxPxURsDd73ewK5jxSyLy+LPhBwqNFrTYyL91cyK9mdGpG+T3JQpb60npaCKb24cwYQwD7O8TiGE6JQZjU6uVi5Eu3g62nDvtFDumNSXfw7k8vXWY8SmlbBqbzar9mYzyM+JBaODuTTSt91bPnV6Ax+tO8K7qw+jN0CQmx3vXzm0SS5GY7O4M81olNXU8+pfhwC4Z2qoKcgAUCoVjOzjxsg+bjw/cyD/Hcxj+Z4sNhwuYG9mGXszy/i/3w8yKdyTWdF+TInwJMLbkZSCKg7nVUigIYTocr23oYQ451lZKJkR6cuMSF/2Z5XxzbZjrIzPZn9WOY/8so9X/jzEvOGBXDMqEH8Xu1afN6eshvt+iDdVs5w11I8XLhvUrBOpb0OgkVN2+kDj3dWHKayso4+HPTeeZqeIjaXK9HoKKjT8tjebZXsy2Z9VzupDeaw+lIeTjQXOdsbZjaQTElKFEKKrSFM1cU4pqarjx9gMlmxLM20jVSpg4eR+3D8t7Iwluv85kMujv+6jtLoeeysV/3fZIGZF+7d4bFx6CbM+3oqfsy1bHpvS4jGJueVMf38zOr2BJTeNYHxo22cgDudVsCwui5XxWeSU1ZrujwxwZuXCsW0+nxBCtKTT62gI0RO52Ftx+8S+3DK+D2sO5fH1tmNsOVLEB2uPcCC7nHfmRaG2bV7gqrZex4t/HOTb7ekADPFX8/6VQ0/b9K1x6SS3vBatTt+sqJjBYOCZFQfQ6Q1cNMi7XUEGQJiXI49dFMHDF4SzPaWIZXFZ/Hswl/7e3bdyqhDi3CGBhjgnqZQKzh/ozfkDvVm+J5PHfk1gbWI+l320hc8WDKOf5/GLdFJuBfcs3UNSnnEp4raJfXjwvPAzbpv1cLDGUqWgXmcgv0JjWkpptDI+m53HirG1VPHUJQPM8prG9nNv6KESedbnE0IIc+hedZuF6AKXD/Xn1zvG4Ku2IbWwiss+2sq/B3IxGAx8uz2NSz/cTFJeBe4O1nxz4wgev6h/q2pzKJUKvNXG7aUnJ4RW1Nbz0p/GBNC7pvQzzX4IIURvIzMaQgCD/NSsunscC7+LY0dqMbcu2d3k6xPDPHhrbiTuDm0rp++jtiWjuIbsE3InAN5fk0xBhYZgNztuHi+lwoUQvZfMaAjRwN3Bmm9vHslA36ZJTvdNC+Wr64e3OciAlre4JudV8NWWYwA8e+lArC2kq6oQoveSQEOIBlqdng/WHuFQTnmT+3/bm01qUVW7zunr3HTpxGAw8MzKA2j1Bs4b4MXkcM+zG7QQQnRzEmgIAWSWVHPl4u28vyYZvQHmDPNn6S2j8FHbcLSgiss+3MLqg3ltPq/vSTMav+/LYVtKEdYWSp4xQwKoEEJ0dxJoiHPenwk5XPzeJmLTSnC0tuC9K6N4Y04ko/u6sequcYwIdqVCo+Xmb2KNgYi+9aVnfNWNgUYtVRotL/1hTAC9Y1JfAlxbXyRMCCF6Kgk0xDmrpk7H48v2ced3cZTXaokKcOaPe8YzM8rPdIyHozFvY8HoIADe/u8wt3+7m8oTeo6cjmlGo6yGD9YeIbe8lgBXW26f2Nf8L0gIIbohCTTEOamitp5LP9zM0p0ZKBRw56S+/Hz7aALdms8yWFkoeWHmIF6fPQQrlZJ/D+Zx+UdbSC08c95GY45GaXU9n244CsCzlwxsd48VIYToaSTQEC2q1+mpqdN19TA6TFJuBcn5lQAMD3bl7imhWKpO/+swd3gAP942Ci8na5LzK7n0w82sS8w/7WMcbSxxPKEHypQIT6YN8Dr7FyCEED2E9DoRzZRU1TH17Q0UV9VhY6nE1c4KZzsrXO2tcLazxNXeChc7K1zsLHGxtzp+294KVzsrbK26/6d1g8HYffXt/4zdVyO8Hfno6mj6ejic8bH5FbXc8W0cu9NKUCjgofPDuXNS31O2ng9+7A/T/69/aNJpy5YLIUR3Jb1OhNlYnlD1srZeT3ZZbbOCU6djbaFsCEqscLW3bAhKGgMRY3DiclLgYmupOuWFuiMoFArumhJKdJAL9yyNJzG3gks/2Myrs4cwI9L3tI/1dLRh6S2jeP63A3y3I503/klif1YZb86JxP6kDq4nzgp5OFpLkCGEOOfIjIZoUWJuOdd8voPCyjocrS14ZsYALFVKiqvqKKlu+FdV3+x2nU7fruezsjDOnBiDEEvT7MiJsybOdlYNsyvG4MTOyjzBSX55LXcv3WNq+37d6CCenTHwjJ1cAZbuTOeZlfup1xkI83Jg8bUxTYKJN/9J4sN1RwC4ZXwIT06XLa1CiJ6pvddvCTTEKR0tqOTqz3aQW15LsJsd390y6rQ9OQwGA9V1uhOCj3pKquoorqqjtLqO4oZgpKS67vgxZxmcuNhZmmZHjLMmlkT6OzMnJqBN59Lq9Lz572FTwuayO8cQHejSqsfuTivm9m/jKKjQ4GRjwfvzhzIp3JPUwioueGej6fXNjvbnrbln1+xMpzcYv5dVx7+HxQ3f06LKuibf28ZjQr0c+fm20a3qzyKEEKciSyfC7Pp6OPDTbaO56vPtHCuqZu6n2/j+lpEEubU8/a9QKLC3tsDe2qLVNSJODE5Kq+sprq4zXUhLqozBijFAOSFwqa6jTqunTqsnr1xDXrmmyTm/JZ0Bvk4M9FW3+rVaqJSEeRnzM1ztrYhoQ4v1YUGu/H73OG7/djd70ku54X+7ePiCcHamFjcJok5urGYwGKjQaE3BWNNg4fhrbfxeFFfXUVZTT1s/GhRWaOjEVSkhhGhCZjTEGWWX1nD15ztILazCy8ma724eRT/PMydNdhSDwUBNfcPMScOn+cZP8MviskjIKuOeqaE8cF5Yq8+p0xs4750NpBRU8ciF4dw5qV+bx6XR6nh25QF+2JXR5H4ftQ05DTkuo/u4NZl1qNe179dPoeC0AUcfD3smhHowMcyDUX3cekSCrhCie5OlE9Gh8itquebzHRzOq8TN3opvbx5Jf5/u9/P7ZXcmD/28l/4+Tvx17/hWP27V3mzuWboHta0lWx6bgoN1+yb7DAYD3+1I56kV+1v9GDsrFS52Vrg5WDVZBnK1t8TV3hpXe0tsrSxIzqvgQHY5ezNLSSloWsPD0caCsX3dmRDmwYQwd/xdpOqoEMK8ZOlEdChPRxt+uHU0136xgwPZ5Vy5eDtLbhrBEH/nrh5aE1MjPFEq4FBOORnF1a1awtHrDXy4NhmAm8aFtDvIAOPy0TWjgkjILOPH2IxmX3/6kgGEeTngesK24JaKdxkMBpLzK9l4uIC/9uewM7UYjfb4MoxCAZH+zsbAItSdqABnLM5QB0QIIbqCBBqi1Vztrfj+llFc/9VO9qSXcvVnO/jqhuHEBLt29dBMXOytGB7syo7UYv47mMeN40LO+Jh/D+ZyOK8SR2sLrhsTbJZxvHbFEO47L5Tbv41jb0ap6f6YIBciA5xbfExJVR1bjhay8XABm5ILTcstjbydbJgQZpy1GNfPHWc7K7OMVQghOpIsnYg2q9Rouel/u9iRWoytpYovrothTD/3rh6WyRebU/m/3w8yqo8rP9w6+rTHGgwGpr+/mYM55dw9pR8Pnh9u1rHU1ut4esV+ft6dCRh3yux95nxsrVRodXriM0rZeLiADcmF7MssbZJ3YW2hZGQfNyaEGoOLUE+HTq01IoQQJ5IcDdGpaup03Loklk3JhVhZKHl6en+uGhmEqhW1JzpaRnE1419fh0qpYPdT0077yX/1wTxu/iYWeysVmx+dgou9+WcJDAYDIY//2eS+QX5OpBVVU1HbtDlbmJcDE0I9mBDmwYgQV+mJIoToNiRHQ3QqWysVn18Xw13f7+G/g3k8vfIA3+/M4LkZAxjZx61LxxbgakeEtyOJuRWsTcxnVrR/i8cZDAbeb8jNuHZ0cIcEGWDM27h1Qh8Wb0wx3bc/qxwAZztLxvVzZ0KoB+PD3PFRn7pOiRBC9ESSPSbazdpCxSdXR/PCzIGobS05lFPOvMXbuXvpnmY1Izrb+Q2Ny/49kHfKYzYcLmBfZhm2lipuHn/mXI6zER3o3OL9d07qywfzhzJ3eIAEGUKIXkkCDXFWLFRKFowOZt1Dk7h6ZCAKBfy2N5upb23ggzXJ1NZ3TQfY8wZ4A7AxuaDFMRgMBt5fY5zNuHpkIO4O1h06ngsGerP6gYnsffZ8Ev/vQmY3zLK8/Gci9/8Y32XfJyGE6GgSaAizcLW34qXLB/P73eMYEexKTb2Ot/47zHnvbOCfA7l0cioQg/yc8FHbUF2nY8uRwmZf33q0iLj0UqwslNw6oU+Hj0ehUNDP0wG1rSU2lirenDOEZ2cMQKVUsCI+mys+3UpWF88CCSFER5BAQ5jVQF81P942ivfnD8XbyYaM4hpuW7Kba7/YSXJeRaeNQ6FQcF7D8sl/B5svn7zXMJtx1YhAPJ1sOm1cjRQKBTeMDeHbm0biam/F/qxyZnywmW1Hizp9LEII0ZEk0BBmp1AouDTSl7UPTeTuKf2wslCy+UghF763iRd+O0hZTX2njOP8huWT1Yfy0OmPz6jsSCliZ2oxViolt03s+NmM0xnd141Vd41loK8TxVV1XPPFDr7aktrpM0BCCNFRJNAQHcbOyoIHzw9n9f0TOX+AFzq9gS+3pDLlzfX8sDO9ycW/I4zs44qjjQWFlXXEZ5SY7v9grbFt+5wY/26RgOnvYsevd4zh8qF+6PQGnv/tIA/9vE/yNoQQvYIEGqLDBbrZsXhBDEtuGkE/TweKqup4bFkCl320hd1pxR32vJYqJVMiPAH4t2H5ZHdaCZuPFGKhVHDHpL4d9txtZWOp4u25kTw1vT8qpYJf4zKZu2hbl+/eEUKIsyWBhug040M9+Ove8Tx9yQAcrS1IyCpj9ifbuP/HePLKa898gnYw5Wk0bHP9oKFuxqxov27XeEyhUHDz+D58c+MIXOws2ZdZxowPNrMjRfI2hBA9lwQaolNZqpTcNC6EdQ9P4srhASgUsHxPFpPfXM8n64+i0Zp3uWBimAeWKgUphVUs35PJ+qQCVEoFCye3vQ18Zxnbz51Vd42jv48TRVV1XP35Dr7eekzyNoQQPZIEGqJLuDtY8+rsIaxcOJboQGeq63S89nciF7yzkTWH8sx2UXW0sWRMX2Mflsd+TQBgZqQvQW72Zjl/RwlwtWPZHWOYEemLVm/g2VUHJG9DCNEjSaAhutQQf2d+uX0Mb8+NxNPRmmNF1dz0dSw3/G8XRwsqzfIcjcsnGq0ehQIWTum+sxknsrVS8f6VUTxxcQRKBfwal8mcT7dJvQ0hRI8igYbockqlglnR/qx9aBK3T+yLpUrB+qQCLnx3Iy//eYiK2rPbDtsYaABcMsSXvh4OZzvkTmPsk9KXJTeNxMXOkoQsY97G1qPNi5AJIUR3JIGG6DYcrC147KII/r1/IlMiPKnXGVi8MYXJb25gZ2r7d6d4OdkwNcITB2sL7p3aM2YzTja2nzu/3T3OVG/j2i928vmmFMnbEEJ0e9ImXnRb6xLzeeH3g6QWVmFnpeKbG0cQE+zarnPV6/RotHocrHt2w+Laeh1PLE9gWVwWADMifXlt9mDsrHr26xJCdH/tvX5LoCG6tdp6Hbd8E8um5ELsrVR8c9NIhgW5dOmYKmrreeWvRKxUSkaEuDI82BUPx45tynYig8HA11uP8eIfh9DqDUR4O7L42hgC3brXdl0hRO8igYbotWrqdNz09S62Hi3C0dqCJTePJCrAucvGc/+P8Szfk9XkvhB3e2KCXBge4sqIYFeC3OxQKBQdOo4dKUUs/D6Owso61LaWvD9/KBPDPDr0OYUQ5y4JNESvVl2n5YavdrEjtRhHGwu+v3kUg/3VnT6OlfFZ3PtDPEoFzI72JyGrjKS8Ck7+LfJwtGZ4sAvDg40zHv19nFApzR945JbVcvu3u4nPKEWhgIfOD+fOSX07PMgRQpx7JNAQvV6VRsv1X+1k17ES1LaWfHfzSAb5dV6wkVFczcXvbaJCo+W+aaHcNy0MgLLqenanF7MztYRdx4rZl1lKva7pr5WDtQXRQS6MaAg+IgOcsbFUmWVcGq2O51YdYOnODAAuHOjNm3Mje3w+ihCie5FAQ5wTKjVaFnyxg7j0UpztLPn+5lEM8O3495FWp+fKxduJTSshOtCZn24bjYWq5U1btfU69maUsutYMbuOlbA7rYRKjbbJMVYqJYP91Q0zHi7EBLmitrM8qzEu3ZnOsysPUKfT08/TgUXXDutRW3mFEN2bBBrinFFRW8+1X+wkPqMUV3srlt4yinBvxw59zvfXJPP2f4dxsLbgr3vHE+Da+sRLnd7AoZxyYhsCj53Hiimo0DQ5RqGAcC9Hhge7EhPswogQ13Z1lo1LL+GOb3eTV67B0dqCd+ZFMe2EOiJCCNFeEmiIc0pZTT3XfrGDfZlluNlb8cOtowj16phgIy69hDmfbkOnN/DOvEguH+p/VuczGAykFVU3zHgYg4/Uwqpmx/m72DIi2JWYYFdGhLjQ18OhVbkX+RW1LPwujl3HSgC4Z2oo900NRdkBOSJCiHOHBBrinFNWXc9Vn2/nQHY57g7W/HDrKPp5mnepoFKj5eL3NpFeXM2lkb68d2VUhyRaFlRoiD1WzM6G4ONgdjn6k34zXe2tjDtbgl0ZHuLKQF8nLE+xfFOn1fPSHwf5elsaAFMjPHl7XhRq27NbnhFCnLsk0BDnpJKqOq76fAeHcsrxdLTmx9tGE+JuvoZpD/60l1/jMvFztuXPe8d32oW6UqMlLq3ENOuxJ70UjVbf5BhbSxVDA50ZHuzKiBBXhgY6Nyvc9cvuTJ5cnoBGqyfE3Z5F1w4jrINmfoQQvZsEGuKcVVxVx1WfbScxtwJvJxt+vG2UWbqz/rY3m7uX7kGpgB9uHc2IkPZVJTWHOq2ehKwydh0rNuV6lNU07QGjUioY5OtkmvEYHuyKq70VCZll3P7tbrJKa7CzUvHmnEguHuzTRa9ECNFTSaAhzmmFlRrmL95Ocn4lvmobfrxtdJsSNk+WVVrDhe9upKJWy91T+vHg+eFmHO3Z0+sNJOdXHs/zSC0mu6y22XF9PewZEeJKXw8Hvt2exrGiagBun9iXhy8I75DaHkKI3kkCDXHOK6jQcOXibRwtqMLP2ZYfbxuFv0vbgw2d3sD8z7azM7WYqABnfr599ClzIbqTrNIadqU25HmkFpOcX3na48eHuvP+lUNxsbfqpBEKIXoyCTSEAPLLa7ly8XZSCqsIcLXlx1tH4+vctm2iH607whv/JGFvpeLPe8ebZRmmK5RU1RF7Qp5HQmYZ2pMyTAf6OvHbXeNkR4oQ4ozae/2W0oGiV/F0suH7W0Yxb/E20oqqmf/Zdn68dTTeaptWPX5vRinv/HcYgOdnDuqxQQaAi70V5w3w4ryGOho1dTr2ZJQQe8wYfMSllWChVCCN5oUQHUlmNESvlF1aw7zF28goriHE3Z4fbx2Fp9Ppg40qjZbp72/iWFE104f48OH8ob26Z4heb5CZDCFEq7X3+t39F56FaAdfZ1uW3jIKP2dbUgurmP/ZdvIrmidLnuj53w5wrKgaX7UNL182uFcHGYAEGUKITiGBhui1/F3s+OFWY7BxtKCKqz/bQWGlpsVj/0zI4afYTBQKjIWt/r+9+w+N+r7jOP460+bi9HLlNImGXKJW1Fm5OI29hrbOn5WjZJX90U4yTEvnHyOK7vAP758mQiGCDLQkldAN888yLaWJUGidKE3WoW0SuRFlilrBFGNis3nxbvWU3O2PrtcFZc3X5nPfS77PBxx4X+573zd8Q3yS7/fu8yPXHQEAfIvQwLTm9/1E7TuCmu8t0JXhuGrf+1z/TNwf95rB2DeKfNgvSfrtz5/Wc4vm2DEqAExLhAamvYo5s9S+4zmVFLp1eeiuav/wuf7139gYS6UVPv53xb55oECZV7/bvMTmaQFgeiE04AgL534bG0Uet/4xOKpf//Fzxf79QO/99Uud/XJEM5/M0+Ff/WxKfF8GAEwl/FaFYzxdNFt/3hHU3Nn5unhzVK+2ntXv/3JZktT4i+WTukYKAOBbhAYcZXGxR+07npNvVr4uD93Vg7G0Qivm6dUqv92jAcC0RGjAcZaUePSn3wRV7HFrUdEsNf1y+n+UFQDswjeDwpF+Or9Qf9u3Qem0lP8EvQ0Aplj+Ddvd3a2amhqVlpbK5XKps7PTwFiAeU/mzSAyAMAwy79lE4mEKisr1dLSYmIeAAAwjVi+dBIKhRQKhSb8+mQyqWTy+29jHB0dtXpIAAAwRRn/u3FTU5O8Xm/m4fdzdz8AAE5hPDQikYhisVjmMTAwYPqQAAAgRxj/1Inb7Zbb7TZ9GAAAkIO45R4AABhDaAAAAGMsXzqJx+O6evVq5vn169cVjUbl8/lUXl4+qcMBAICpzXJo9Pb2av369Znn4XBYklRXV6e2trZJGwwAAEx9lkNj3bp1SqfTJmYBAADTDPdoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwBhCAwAAGENoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwBhCAwAAGENoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwBhCAwAAGENoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwBhCAwAAGENoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwBhCAwAAGENoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwBhCAwAAGENoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwBhCAwAAGENoAAAAYwgNAABgDKEBAACMITQAAIAxhAYAADCG0AAAAMYQGgAAwJjHCo2WlhYtWLBABQUFCgaD+uKLLyZ7LgAAMA1YDo3jx48rHA6roaFB58+fV2VlpbZs2aLh4WET8wEAgCnMlU6n01Z2CAaDWrNmjZqbmyVJqVRKfr9fu3bt0r59+x56fTKZVDKZzDyPxWIqLy/XwMCACgsLf+T4AAAgG0ZHR+X3+3Xnzh15vd4J7/eElYPcv39ffX19ikQimW0zZszQpk2bdPbs2Ufu09TUpP379z+03e/3Wzk0AADIASMjI+ZC4+uvv9bY2JhKSkrGbS8pKdGlS5ceuU8kElE4HM48v3PnjioqKnTjxg1Lg2LyfVen/HXJfpyL3MG5yB2ci9zy3RUJn89naT9LofE43G633G73Q9u9Xi8/ODmisLCQc5EjOBe5g3OROzgXuWXGDGu3d1p69dy5c5WXl6ehoaFx24eGhjRv3jxLBwYAANOfpdDIz8/X6tWrdfr06cy2VCql06dPq7q6etKHAwAAU5vlSyfhcFh1dXWqqqrSs88+q0OHDimRSOiNN96Y0P5ut1sNDQ2PvJyC7OJc5A7ORe7gXOQOzkVuedzzYfnjrZLU3NysgwcP6tatW1q5cqXeeecdBYNBq28DAACmuccKDQAAgIlgrRMAAGAMoQEAAIwhNAAAgDGEBgAAMCarocHy8rmhu7tbNTU1Ki0tlcvlUmdnp90jOVZTU5PWrFkjj8ej4uJibd26VZcvX7Z7LEc6cuSIAoFA5lsoq6ur9fHHH9s9FiQdOHBALpdLe/bssXsUx2lsbJTL5Rr3WLZsmaX3yFposLx87kgkEqqsrFRLS4vdozheV1eX6uvrde7cOZ06dUoPHjzQSy+9pEQiYfdojlNWVqYDBw6or69Pvb292rBhg1555RVdvHjR7tEcraenR62trQoEAnaP4ljPPPOMBgcHM4/PPvvM0v5Z+3ir1eXlkR0ul0sdHR3aunWr3aNA0u3bt1VcXKyuri6tXbvW7nEcz+fz6eDBg3rzzTftHsWR4vG4Vq1apXfffVdvv/22Vq5cqUOHDtk9lqM0Njaqs7NT0Wj0sd8jK3/R+G55+U2bNn1/4B9YXh5wolgsJkmWV0fE5BobG9OxY8eUSCRYXsFG9fX1evnll8f934Hsu3LlikpLS7Vo0SLV1tbqxo0blvY3vnqr9HjLywNOk0qltGfPHj3//PNasWKF3eM4Un9/v6qrq3Xv3j3Nnj1bHR0dWr58ud1jOdKxY8d0/vx59fT02D2KowWDQbW1tWnp0qUaHBzU/v379eKLL+rChQvyeDwTeo+shAaAH1ZfX68LFy5Yvv6JybN06VJFo1HFYjF98MEHqqurU1dXF7GRZQMDA9q9e7dOnTqlgoICu8dxtFAolPl3IBBQMBhURUWF3n///QlfUsxKaLC8PPD/7dy5Ux999JG6u7tVVlZm9ziOlZ+fr8WLF0uSVq9erZ6eHh0+fFitra02T+YsfX19Gh4e1qpVqzLbxsbG1N3drebmZiWTSeXl5dk4oXM99dRTWrJkia5evTrhfbJyjwbLywOPlk6ntXPnTnV0dOjMmTNauHCh3SPhf6RSKSWTSbvHcJyNGzeqv79f0Wg086iqqlJtba2i0SiRYaN4PK5r165p/vz5E94na5dOfuzy8pg88Xh8XI1ev35d0WhUPp9P5eXlNk7mPPX19Wpvb9eJEyfk8Xh069YtSZLX69XMmTNtns5ZIpGIQqGQysvLdffuXbW3t+vTTz/VyZMn7R7NcTwez0P3Kc2aNUtz5szh/qUs27t3r2pqalRRUaGbN2+qoaFBeXl52rZt24TfI2uh8dprr+n27dt66623MsvLf/LJJw/dIArzent7tX79+szzcDgsSaqrq1NbW5tNUznTkSNHJEnr1q0bt/3o0aN6/fXXsz+Qgw0PD2v79u0aHByU1+tVIBDQyZMntXnzZrtHA2zz1Vdfadu2bRoZGVFRUZFeeOEFnTt3TkVFRRN+D5aJBwAAxrDWCQAAMIbQAAAAxhAaAADAGEIDAAAYQ2gAAABjCA0AAGAMoQEAAIwhNAAAgDGEBgAAMIbQAAAAxhAaAADAmP8A6mdFLA8/F7YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pos[0], pos[1])\n",
    "plt.xlim(0,env.L); plt.ylim(0,env.L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export ; nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_opts_main",
   "language": "python",
   "name": "rl_opts_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
