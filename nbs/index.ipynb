{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a2a706-236f-4b46-b77c-2b9a7fa527c4",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"350\" src=\"https://github.com/gorkamunoz/rl_opts/blob/master/nbs/figs/logo_midjourney_scaled.png?raw=true\">\n",
    "</p>\n",
    "<h1 align=\"center\">RL-OptS</h1>\n",
    "<h4 align=\"center\">Projective Simulation and Reinforcement Learning of Optimal Search strategies</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7ad7c-f68f-4881-8a57-3bf626dab4d9",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a href=\"https://zenodo.org/badge/latestdoi/424986383\"><img src=\"https://zenodo.org/badge/424986383.svg\" alt=\"DOI\"></a>\n",
    "  <a href=\"https://badge.fury.io/py/rl_opts\"><img src=\"https://badge.fury.io/py/rl_opts.svg\" alt=\"PyPI version\"></a>\n",
    "  <a href=\"https://badge.fury.io/py/b\"><img src=\"https://img.shields.io/badge/python-3.9-red\" alt=\"Python version\"></a>\n",
    "</p>\n",
    "\n",
    "\n",
    "This library builds the necessary tools needed to study, replicate and\n",
    "develop Projective Simulation agents for learninng efficient strategies in target search problems, as\n",
    "well as a benchmark baselines with which to compare the. This library is\n",
    "based in three different publications:\n",
    "\n",
    "- [“Optimal foraging strategies can be learned”](https://arxiv.org/abs/2303.06050) by *G. Muñoz-Gil, A. López-Incera, L. J. Fiderer* and *H. J. Briegel* (2024). Here we developed\n",
    "  agents able to learn how to forage efficiently in environments with multiple targets.\n",
    "\n",
    "- [\"Learning how to find targets in the micro-world: the case of intermittent active Brownian particles\"](https://pubs.rsc.org/en/content/articlehtml/2024/sm/d3sm01680c) by *M. Caraglio, H. Kaur, L. Fiderer, A. López-Incera, H. J. Briegel, T. Franosch*, and *G. Muñoz-Gil* (2024). In this case, we study the ability of agents to learn how to switch from passive to active diffusion to enhance their target search efficiency.\n",
    "\n",
    "- [“Learning to reset in target search problems”](https://arxiv.org/abs/2503.11330) by *G. Muñoz-Gil, H. J. Briegel* and *M. Caraglio* (2025). Here we extended the agents to be able to\n",
    "  reset to the origin, a feature that has revolutionize target search problems in the last years.\n",
    "  \n",
    "- [“Run-and-Tumble Particles Learning Chemotaxis”](https://arxiv.org/pdf/2507.23519) by *N. Tovazzi, G. Muñoz-Gil and *M. Caraglio* (2025). In this work we explore the ability of active particles to adapt their run-and-tumble strategy to reach targets, based on their chemotactic response, just as bacteria do in the real world!\n",
    "\n",
    "\n",
    "\n",
    "### Installation\n",
    "\n",
    "You can access all these tools installing the python package `rl_opts` via Pypi:\n",
    "```python\n",
    "pip install rl-opts\n",
    "```\n",
    "You can also opt for cloning the [source repository](https://github.com/gorkamunoz/rl_opts) and executing the following on the parent folder you just cloned the repo:\n",
    "```python\n",
    "pip install -e rl_opts\n",
    "```\n",
    "This will install both the library and the necessary packages. \n",
    "\n",
    "### Tutorials\n",
    "\n",
    "We have prepared a series of tutorials to guide you through the most important functionalities of the package. You can find them in the [Tutorials folder](https://github.com/gorkamunoz/rl_opts/tree/master/nbs/tutorials) of the Github repository or in the Tutorials tab of our [webpage](https://gorkamunoz.github.io/rl_opts/), with notebooks that will help you navigate the package as well as reproducing the results of our paper via minimal examples. In particular, we have three tutorials:\n",
    "\n",
    "- <a href=\"tutorials/tutorial_learning.ipynb\" style=\"text-decoration:none\">Learning to forage with RL </a> : shows how to train a RL agent based on Projective Simulation agents to search targets in randomly distributed environments as the ones considered in our paper.\n",
    "- <a href=\"tutorials/tutorial_reset.ipynb\" style=\"text-decoration:none\">Learning to reset in target search problems </a> : shows how to train a RL agent similar to the previous, but with the ability to reset to the origin, an action that is learned along its spatial dynamics.\n",
    "- <a href=\"tutorials/tutorial_imitation.ipynb\" style=\"text-decoration:none\">Imitation learning </a> : shows how to train a RL agent to imitate the policy of an expert equipped with a pre-trained policy. The latter is based on the benchmark strategies common in the literature.\n",
    "- <a href=\"tutorials/tutorial_benchmarks.ipynb\" style=\"text-decoration:none\">Forangin benchmarks: beyond Lévy walks </a> : shows how launch various benchmark strategies with which to compare the trained RL agents.\n",
    "\n",
    "\n",
    "\n",
    "### Cite\n",
    "\n",
    "We kindly ask you to cite us if any of the previous material was useful for you. You can either cite this library:\n",
    "``` latex\n",
    "@software{rlopts,\n",
    "  author       = {Mu\\~noz-Gil, Gorka and L\\'opez-Incera, Andrea and Caraglio Michele and Fiderer, Lukas J. and Briegel, Hans J.},\n",
    "  title        = {\\uppercase{RL}-\\uppercase{O}pt\\uppercase{S}: Reinforcement Learning of Optimal Search Strategies},\n",
    "  month        = jan,\n",
    "  year         = 2024,\n",
    "  publisher    = {Zenodo},\n",
    "  version      = {v1.0},\n",
    "  doi          = {10.5281/zenodo.10450489},\n",
    "  url          = {https://doi.org/10.5281/zenodo.7727873}}\n",
    "```\n",
    "\n",
    "or the works it's based on:\n",
    "``` latex\n",
    "@article{munoz2024optimal,\n",
    "  title={Optimal foraging strategies can be learned},\n",
    "  author={Mu{\\~n}oz-Gil, Gorka and L{\\'o}pez-Incera, Andrea and Fiderer, Lukas J and Briegel, Hans J},\n",
    "  journal={New Journal of Physics},\n",
    "  volume={26},\n",
    "  number={1},\n",
    "  pages={013010},\n",
    "  year={2024},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "```\n",
    "\n",
    "```latex\n",
    "@misc{munoz2025learning,\n",
    "      title={Learning to reset in target search problems}, \n",
    "      author={Gorka Muñoz-Gil and Hans J. Briegel and Michele Caraglio},\n",
    "      year={2025},\n",
    "      eprint={2503.11330},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cond-mat.stat-mech},\n",
    "      url={https://arxiv.org/abs/2503.11330}, \n",
    "}\n",
    "```\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
