{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fbf0e6c-83c4-4cc1-a577-5a3a1a5da1f8",
   "metadata": {},
   "source": [
    "# Developing from the current library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e71431-bbf7-4472-8728-83c3626b3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rl_opts.rl_framework import TargetEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878259c-de58-4475-9684-de7873e69b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveEnv(TargetEnv):\n",
    "    \n",
    "    def __init__(self, peclet, phase = 'active', **kwargs):\n",
    "        super().__init__(lc = 0, **kwargs) # You need to manually override lc, because now you don't need it\n",
    "        \n",
    "        # Some new variables\n",
    "        self.peclet = peclet        \n",
    "        # You could add the current phase as internal variable\n",
    "        self.phase = phase\n",
    "    \n",
    "    ''' Now we override the functions you need. In this case, you just need update_pos and check_encounters:'''\n",
    "    def update_pos(self, action):\n",
    "        if self.phase == 'active':\n",
    "            print(f'we go FAST to {action}')\n",
    "        if self.phase == 'passive':\n",
    "            print(f'we go SLOW to {action}')\n",
    "       \n",
    "        \n",
    "    def check_encounter(self):\n",
    "        '''Note that the position of the agent and the target are both saved in the environment, so this\n",
    "        functions just needs to check whatever condition you decide, based on internal variables:'''\n",
    "        \n",
    "        # Example with euclidean distance        \n",
    "        if np.linalg.norm(env.positions-env.target_positions) < self.r:\n",
    "            print('Encounter!')\n",
    "        else:\n",
    "            print('You missed the target:(')\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374f51a-c229-44c4-855c-eb81cdb6ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First:\n",
      "we go SLOW to far away\n",
      "Then:\n",
      "we go FAST to not so far away\n",
      "\n",
      "... and now check if we encountered something:\n",
      "You missed the target:(\n"
     ]
    }
   ],
   "source": [
    "#Environment parameters\n",
    "Nt = 1 #number of targets\n",
    "L = 100 #world size\n",
    "r = 50 #target detection radius\n",
    "\n",
    "#Initialize environment\n",
    "env = ActiveEnv(peclet = 1, phase = 'passive', # New variables\n",
    "                Nt = 1, L = L, r = r # Inherited variables\n",
    "               )\n",
    "print('First:')\n",
    "env.update_pos('far away')\n",
    "print('Then:')\n",
    "env.phase = 'active'\n",
    "env.update_pos('not so far away')\n",
    "\n",
    "print('\\n... and now check if we encountered something:')\n",
    "env.check_encounter()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_opts",
   "language": "python",
   "name": "rl_opts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
